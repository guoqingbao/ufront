{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5075a2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 22 15:00:55 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:21:00.0 Off |                  N/A |\n",
      "|  0%   29C    P8    16W / 240W |     46MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eea6c8a",
   "metadata": {},
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dec2cb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: iree-compiler==20230524.529 in /root/anaconda3/lib/python3.9/site-packages (20230524.529)\n",
      "Requirement already satisfied: iree-runtime==20230524.529 in /root/anaconda3/lib/python3.9/site-packages (20230524.529)\n",
      "Requirement already satisfied: PyYAML in /root/anaconda3/lib/python3.9/site-packages (from iree-compiler==20230524.529) (6.0)\n",
      "Requirement already satisfied: numpy in /root/anaconda3/lib/python3.9/site-packages (from iree-compiler==20230524.529) (1.24.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: iree-tools-tf==20230524.529 in /root/anaconda3/lib/python3.9/site-packages (20230524.529)\n",
      "Collecting iree-tools-tflite==20230524.529\n",
      "  Downloading iree_tools_tflite-20230524.529-py3-none-any.whl (3.2 kB)\n",
      "Installing collected packages: iree-tools-tflite\n",
      "Successfully installed iree-tools-tflite-20230524.529\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# For CUDA 11\n",
    "!pip install iree-compiler==20230524.529 iree-runtime==20230524.529 \n",
    "!pip install iree-tools-tf==20230524.529  iree-tools-tflite==20230524.529\n",
    "\n",
    "# For CUDA 12\n",
    "\n",
    "# !pip install iree-compiler==20230815.614 iree-runtime==20230815.614\n",
    "# !pip install iree-tools-tf==20230815.614  iree-tools-tflite==20230815.614\n",
    "# fix issue of iree-benchmark-module for iree-compiler (v20230815.614), depend on the installation of IREE package\n",
    "# ls /opt/conda/lib/python3.10/site-packages/iree/_runtime_libs/\n",
    "# cp /opt/conda/lib/python3.10/site-packages/iree/_runtime_libs/iree-benchmark-module /opt/conda/lib/python3.10/site-packages/iree/runtime/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ff7dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other dependencies for IREE-TF\n",
    "# !pip install tensorflow-cpu==2.13.0 \n",
    "# !pip install tensorflow-addons\n",
    "# !pip install validators\n",
    "# !pip install scipy\n",
    "# !pip install opencv-python\n",
    "# !apt install libgl1 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a869628c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iree-compiler                      20230524.529\n",
      "iree-runtime                       20230524.529\n",
      "iree-tools-tf                      20230524.529\n",
      "iree-tools-tflite                  20230524.529\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep iree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62e77583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow-addons                  0.21.0\n",
      "tensorflow-cpu                     2.13.0\n",
      "tensorflow-datasets                4.5.2\n",
      "tensorflow-estimator               2.13.0\n",
      "tensorflow-io-gcs-filesystem       0.24.0\n",
      "tensorflow-metadata                1.7.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0669c8-dfdc-4c32-8f92-22f79711e87a",
   "metadata": {},
   "source": [
    "# IREE-TF (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fbe0342-6cf1-4fcc-b18e-f6e34647063e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnski96_3.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnski96_3.sm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model MobileNetV3 - Total Time: 22.685s\n",
      "Performing benchmark...\n",
      "Calculating forward latency:\n",
      "  77.8 ms ± 299 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpeopriwdk.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpeopriwdk.sm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model ResNet50 - Total Time: 18.991s\n",
      "Performing benchmark...\n",
      "Calculating forward latency:\n",
      "  204 ms ± 305 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp2i93g1jp.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp2i93g1jp.sm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model SqueezeNet - Total Time: 6.337s\n",
      "Performing benchmark...\n",
      "Calculating forward latency:\n",
      "  82.1 ms ± 466 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpt9b_fdzd.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpt9b_fdzd.sm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model ShuffleNet - Total Time: 17.519s\n",
      "Performing benchmark...\n",
      "Calculating forward latency:\n",
      "  83.5 ms ± 336 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp9lb0taga.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp9lb0taga.sm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model Inception3 - Total Time: 30.343s\n",
      "Performing benchmark...\n",
      "Calculating forward latency:\n",
      "  166 ms ± 798 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpu0959bvn.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpu0959bvn.sm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model DenseNet - Total Time: 44.449s\n",
      "Performing benchmark...\n",
      "Calculating forward latency:\n",
      "  178 ms ± 836 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpkzhyg36a.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpkzhyg36a.sm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model Vit - Total Time: 25.910s\n",
      "Performing benchmark...\n",
      "Calculating forward latency:\n",
      "  728 ms ± 1.55 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend\n",
    "from iree.tf.support import module_utils\n",
    "from vit_keras import vit\n",
    "from keras_def import SequentialCNN, ConcatenatedCNN, NestedCNN, ShuffleNet, SqueezeNet_11, ResNet18\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50, ResNet50V2, MobileNetV3Small, DenseNet121, InceptionV3, VGG16\n",
    "channels_first = False\n",
    "\n",
    "model_list = {\"ResNet18\":ResNet18, \"MobileNetV3\":MobileNetV3Small, \"ResNet50\":ResNet50, \"SqueezeNet\":SqueezeNet_11, \"ShuffleNet\":ShuffleNet,\n",
    "              \"Inception3\":InceptionV3, \"DenseNet\":DenseNet121, \n",
    "             \"Vit\":vit.vit_b16}\n",
    "\n",
    "INPUT_SHAPE = [1, 3, 224, 224] if channels_first else [1, 224, 224, 3]\n",
    "backend.set_image_data_format('channels_first' if channels_first else 'channels_last')\n",
    "x_train = np.random.uniform(low=0.0, high=1.0, size=(1, 3, 224, 224) if channels_first else (1, 224, 224, 3)).astype(np.float32)\n",
    "\n",
    "for modelname, Model in model_list.items():\n",
    "    \n",
    "    if modelname == \"Vit\":\n",
    "        model = Model(image_size=224, activation='relu', pretrained=False, include_top=True, pretrained_top=False, channel_first=channels_first)\n",
    "    elif modelname == \"SqueezeNet\":\n",
    "        model = Model(input_shape=tuple(INPUT_SHAPE[1:]), nb_classes=1000, channel_first=channels_first)\n",
    "    elif modelname == \"ShuffleNet\":\n",
    "        model = Model(include_top=True, input_shape=tuple(INPUT_SHAPE[1:]))\n",
    "    elif modelname == \"ResNet18\":\n",
    "        model = Model(classes=1000, input_shape=tuple(INPUT_SHAPE[1:]))\n",
    "    else:\n",
    "        model = Model(weights=None, include_top=True, input_shape=tuple(INPUT_SHAPE[1:]))\n",
    "        \n",
    "    t1_start = time.perf_counter()\n",
    "    # Wrap the model in a tf.Module to compile it with IREE.\n",
    "    class Module(tf.Module):\n",
    "      def __init__(self):\n",
    "        super(Module, self).__init__()\n",
    "        self.m = model\n",
    "        self.m.predict = lambda x: self.m.call(x, training=False)\n",
    "        self.predict = tf.function(\n",
    "            input_signature=[tf.TensorSpec(INPUT_SHAPE, tf.float32)])(model.predict)\n",
    "    \n",
    "    backend_choice = \"iree_llvmcpu (CPU)\" #@param [ \"iree_vmvx (CPU)\", \"iree_llvmcpu (CPU)\", \"iree_vulkan (GPU/SwiftShader)\" ]\n",
    "    backend_choice = backend_choice.split(\" \")[0]\n",
    "    backend = module_utils.BackendInfo(backend_choice)\n",
    "    compiled_model = backend.compile_from_class(Module, [\"predict\"])\n",
    "    t1_stop = time.perf_counter()\n",
    "    print(\"**** Model {} - Total Time: {:.3f}s\".format(modelname, t1_stop - t1_start)) # print performance indicator\n",
    "\n",
    "    print(\"Performing benchmark...\")\n",
    "    print(\"Calculating forward latency:\\n  \", end=\"\")\n",
    "    %timeit -n 100 compiled_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d51f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e43299e-1c2f-4bc4-b3a5-1ff1fe7360ac",
   "metadata": {},
   "source": [
    "## IREE-TF (GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fd904c",
   "metadata": {},
   "source": [
    "#### Vision Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f6ea541-fdee-4e47-8e55-daee2a1dc71f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 18:01:11.822700: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/root/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/root/anaconda3/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmps93v7um8.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmps93v7um8.sm/assets\n",
      "2024-05-21 18:01:18.248501: I tensorflow/cc/saved_model/bundle_v2.cc:44] Reading SavedModel from: /tmp/tmps93v7um8.sm\n",
      "2024-05-21 18:01:18.259966: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmps93v7um8.sm\n",
      "2024-05-21 18:01:19.107231: W tensorflow/compiler/mlir/tensorflow/transforms/xla_cluster_formation.cc:81] no entry function is found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model ResNet18 - Total Time: 7.177s\n",
      "Calculating forward latency:\n",
      "  ResNet18 - 3.232 ± 0.009 ms\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpd4x5z3_7.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpd4x5z3_7.sm/assets\n",
      "2024-05-21 18:01:45.498474: I tensorflow/cc/saved_model/bundle_v2.cc:44] Reading SavedModel from: /tmp/tmpd4x5z3_7.sm\n",
      "2024-05-21 18:01:45.537594: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmpd4x5z3_7.sm\n",
      "2024-05-21 18:01:46.395873: W tensorflow/compiler/mlir/tensorflow/transforms/xla_cluster_formation.cc:81] no entry function is found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model MobileNetV3 - Total Time: 15.049s\n",
      "Calculating forward latency:\n",
      "  MobileNetV3 - 1.520 ± 0.000 ms\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp7lauxz4e.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7lauxz4e.sm/assets\n",
      "2024-05-21 18:02:13.745904: I tensorflow/cc/saved_model/bundle_v2.cc:44] Reading SavedModel from: /tmp/tmp7lauxz4e.sm\n",
      "2024-05-21 18:02:13.807671: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmp7lauxz4e.sm\n",
      "2024-05-21 18:02:15.882209: W tensorflow/compiler/mlir/tensorflow/transforms/xla_cluster_formation.cc:81] no entry function is found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model ResNet50 - Total Time: 19.173s\n",
      "Calculating forward latency:\n",
      "  ResNet50 - 6.133 ± 0.016 ms\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpsueqp2un.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpsueqp2un.sm/assets\n",
      "2024-05-21 18:02:36.367478: I tensorflow/cc/saved_model/bundle_v2.cc:44] Reading SavedModel from: /tmp/tmpsueqp2un.sm\n",
      "2024-05-21 18:02:36.377542: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmpsueqp2un.sm\n",
      "2024-05-21 18:02:36.595692: W tensorflow/compiler/mlir/tensorflow/transforms/xla_cluster_formation.cc:81] no entry function is found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model SqueezeNet - Total Time: 3.894s\n",
      "Calculating forward latency:\n",
      "  SqueezeNet - 1.390 ± 0.000 ms\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpg2_qwvfp.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpg2_qwvfp.sm/assets\n",
      "2024-05-21 18:03:00.231870: I tensorflow/cc/saved_model/bundle_v2.cc:44] Reading SavedModel from: /tmp/tmpg2_qwvfp.sm\n",
      "2024-05-21 18:03:00.276356: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmpg2_qwvfp.sm\n",
      "2024-05-21 18:03:01.214831: W tensorflow/compiler/mlir/tensorflow/transforms/xla_cluster_formation.cc:81] no entry function is found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model ShuffleNet - Total Time: 15.533s\n",
      "Calculating forward latency:\n",
      "  ShuffleNet - 2.480 ± 0.000 ms\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpvkbxwqx7.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpvkbxwqx7.sm/assets\n",
      "2024-05-21 18:03:35.728424: I tensorflow/cc/saved_model/bundle_v2.cc:44] Reading SavedModel from: /tmp/tmpvkbxwqx7.sm\n",
      "2024-05-21 18:03:35.813632: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmpvkbxwqx7.sm\n",
      "2024-05-21 18:03:38.444018: W tensorflow/compiler/mlir/tensorflow/transforms/xla_cluster_formation.cc:81] no entry function is found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model Inception3 - Total Time: 28.349s\n",
      "Calculating forward latency:\n",
      "  Inception3 - 11.900 ± 0.000 ms\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp3db1ueu5.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp3db1ueu5.sm/assets\n",
      "2024-05-21 18:04:28.626842: I tensorflow/cc/saved_model/bundle_v2.cc:44] Reading SavedModel from: /tmp/tmp3db1ueu5.sm\n",
      "2024-05-21 18:04:28.755830: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmp3db1ueu5.sm\n",
      "2024-05-21 18:04:31.389322: W tensorflow/compiler/mlir/tensorflow/transforms/xla_cluster_formation.cc:81] no entry function is found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model DenseNet - Total Time: 41.106s\n",
      "Calculating forward latency:\n",
      "  DenseNet - 7.166 ± 0.007 ms\n",
      "INFO:tensorflow:Assets written to: /tmp/tmporxwsvkb.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmporxwsvkb.sm/assets\n",
      "2024-05-21 18:05:16.128203: I tensorflow/cc/saved_model/bundle_v2.cc:44] Reading SavedModel from: /tmp/tmporxwsvkb.sm\n",
      "2024-05-21 18:05:16.247636: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmporxwsvkb.sm\n",
      "2024-05-21 18:05:22.984023: W tensorflow/compiler/mlir/tensorflow/transforms/xla_cluster_formation.cc:81] no entry function is found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model Vit - Total Time: 34.160s\n",
      "Calculating forward latency:\n",
      "  Vit - 33.380 ± 0.087 ms\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import iree\n",
    "import numpy as np\n",
    "from iree import runtime\n",
    "from tensorflow.keras import backend\n",
    "from iree.tf.support import module_utils\n",
    "from vit_keras import vit\n",
    "from keras_def import SequentialCNN, ConcatenatedCNN, NestedCNN, ShuffleNet, SqueezeNet_11, ResNet18\n",
    "from benchmark import benchmark_module\n",
    "from tensorflow.keras.applications import ResNet50, ResNet50V2, MobileNetV3Small, DenseNet121, InceptionV3, VGG16\n",
    "channels_first = True\n",
    "model_list = {\"ResNet18\":ResNet18, \"MobileNetV3\":MobileNetV3Small, \"ResNet50\":ResNet50, \"SqueezeNet\":SqueezeNet_11, \"ShuffleNet\":ShuffleNet,\n",
    "              \"Inception3\":InceptionV3, \"DenseNet\":DenseNet121, \n",
    "             \"Vit\":vit.vit_b16} \n",
    "input = np.random.uniform(low=0.0, high=1.0, size=(1, 3, 224, 224) if channels_first else (1, 224, 224, 3)).astype(np.float32)\n",
    "\n",
    "INPUT_SHAPE = [1, 3, 224, 224] if channels_first else [1, 224, 224, 3]\n",
    "backend.set_image_data_format('channels_first' if channels_first else 'channels_last')\n",
    "\n",
    "for modelname, Model in model_list.items():\n",
    "    \n",
    "    if modelname == \"Vit\":\n",
    "        model = Model(image_size=224, activation='relu', pretrained=False, include_top=True, pretrained_top=False, channel_first=channels_first)\n",
    "    elif modelname == \"SqueezeNet\":\n",
    "        model = Model(input_shape=tuple(INPUT_SHAPE[1:]), nb_classes=1000, channel_first=channels_first)\n",
    "    elif modelname == \"ShuffleNet\":\n",
    "        model = Model(include_top=True, input_shape=tuple(INPUT_SHAPE[1:]))\n",
    "    elif modelname == \"ResNet18\":\n",
    "        model = Model(classes=1000, input_shape=tuple(INPUT_SHAPE[1:]))\n",
    "    else:\n",
    "        model = Model(weights=None, include_top=True, input_shape=tuple(INPUT_SHAPE[1:]))\n",
    "        \n",
    "    t1_start = time.perf_counter()\n",
    "    # Wrap the model in a tf.Module to compile it with IREE.\n",
    "    class Module(tf.Module):\n",
    "        def __init__(self):\n",
    "            super(Module, self).__init__()\n",
    "            dict_outputs = False\n",
    "            self.m = model\n",
    "            self.m.predict = lambda x: self.m.call(x, training=False)\n",
    "            \n",
    "        @tf.function(input_signature=[tf.TensorSpec(shape=[1, 3, 224, 224],dtype=tf.float32)])\n",
    "        def predict(self,x):\n",
    "            return self.m.predict(x)\n",
    "    \n",
    "    binary = iree.compiler.tf.compile_module(\n",
    "            Module(),\n",
    "            target_backends=[\"cuda\"],\n",
    "            exported_names=[\"predict\"])\n",
    "\n",
    "    t1_stop = time.perf_counter()\n",
    "    print(\"**** Model {} - Total Time: {:.3f}s\".format(modelname, t1_stop - t1_start)) # print performance indicator\n",
    "\n",
    "    print(\"Calculating forward latency:\\n  \", end=\"\")\n",
    "    module = runtime.load_vm_flatbuffer(binary, driver=\"cuda\")\n",
    "    tms = []\n",
    "    for i in range(10):\n",
    "        ret = benchmark_module(module.vm_module, entry_function=\"predict\", inputs=[\"1x3x224x224xf32=1\"], device=\"cuda\")\n",
    "        tm = ret[0].time\n",
    "        tms.append(float(tm[0:-3]))\n",
    "    print(\"{} - {:.3f} ± {:.3f} ms\".format(modelname, np.mean(tms), np.std(tms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4187cfe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f4822b9",
   "metadata": {},
   "source": [
    "#### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44398303-bf91-4d6d-8e95-2071845f0509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpfnz6cdfj.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpfnz6cdfj.sm/assets\n",
      "2024-05-21 18:10:25.461128: I tensorflow/cc/saved_model/bundle_v2.cc:44] Reading SavedModel from: /tmp/tmpfnz6cdfj.sm\n",
      "2024-05-21 18:10:25.542762: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmpfnz6cdfj.sm\n",
      "2024-05-21 18:10:33.175330: W tensorflow/compiler/mlir/tensorflow/transforms/xla_cluster_formation.cc:81] no entry function is found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model Bert - Total Time: 33.487s\n",
      "Calculating forward latency:\n",
      "  3.34 ms ± 57.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "from bert import BertModelLayer\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from ufront.keras.model import UFrontKeras\n",
    "import iree.compiler as ireec\n",
    "from iree import runtime\n",
    "import time\n",
    "from tensorflow.keras import backend\n",
    "from iree.tf.support import module_utils\n",
    "import iree\n",
    "GPU = True\n",
    "\n",
    "l_bert = BertModelLayer(**BertModelLayer.Params(\n",
    "  vocab_size               = 16000,        # embedding params\n",
    "  use_token_type           = True,\n",
    "  use_position_embeddings  = True,\n",
    "  token_type_vocab_size    = 16000,\n",
    "\n",
    "  num_layers               = 12,           # transformer encoder params\n",
    "  hidden_size              = 768,\n",
    "  hidden_dropout           = 0.1,\n",
    "  intermediate_size        = 4*768,\n",
    "  intermediate_activation  = \"gelu\",\n",
    "\n",
    "  adapter_size             = None,         # see arXiv:1902.00751 (adapter-BERT)\n",
    "\n",
    "  shared_layer             = False,        # True for ALBERT (arXiv:1909.11942)\n",
    "  embedding_size           = None,         # None for BERT, wordpiece embedding size for ALBERT\n",
    "  num_heads = 12,\n",
    "  # name                     = \"bert\"        # any other Keras layer params\n",
    "))\n",
    "\n",
    "input_ids = np.array([[31, 51, 99], [15, 5, 0]], dtype='int32')\n",
    "input_mask = np.array([[1, 1, 1], [1, 1, 0]], dtype='int32')\n",
    "token_type_ids = np.array([[0, 0, 1], [0, 1, 0]], dtype='int32')\n",
    "\n",
    "INPUT_SHAPE = [2, 3]\n",
    "max_seq_len = 3\n",
    "l_input_ids      = keras.layers.Input(shape=(max_seq_len,), dtype='int32')\n",
    "l_token_type_ids = keras.layers.Input(shape=(max_seq_len,), dtype='int32')\n",
    "\n",
    "output = l_bert([l_input_ids, l_token_type_ids])          # [batch_size, max_seq_len, hidden_size]\n",
    "model = keras.Model(inputs=[l_input_ids, l_token_type_ids], outputs=output)\n",
    "\n",
    "t1_start = time.perf_counter()\n",
    "\n",
    "\n",
    "modelname = \"Bert\"\n",
    "BATCH_SIZE = INPUT_SHAPE[0]\n",
    "SEQUENCE_LENGTH = INPUT_SHAPE[1]\n",
    "bert_input = [tf.TensorSpec(shape=[BATCH_SIZE,SEQUENCE_LENGTH],dtype=tf.int32),\n",
    "            tf.TensorSpec(shape=[BATCH_SIZE,SEQUENCE_LENGTH], dtype=tf.int32)]\n",
    "class BertModule(tf.Module):\n",
    "    def __init__(self):\n",
    "        super(BertModule, self).__init__()\n",
    "        dict_outputs = False\n",
    "        self.m = model\n",
    "        self.m.predict = lambda x: self.m.call(x, training=False)\n",
    "        \n",
    "    @tf.function(input_signature=bert_input)\n",
    "    def predict(self,input_word_ids, segment_ids):\n",
    "        inputs = [input_word_ids, segment_ids]\n",
    "        return self.m.predict(inputs)\n",
    "if GPU:\n",
    "    binary = iree.compiler.tf.compile_module(\n",
    "            BertModule(),\n",
    "            target_backends=[\"cuda\"],\n",
    "            exported_names=[\"predict\"])\n",
    "    \n",
    "    t1_stop = time.perf_counter()\n",
    "    print(\"**** Model {} - Total Time: {:.3f}s\".format(modelname, t1_stop - t1_start)) # print performance indicator\n",
    "\n",
    "    \n",
    "    module = runtime.load_vm_flatbuffer(binary, driver=\"cuda\")\n",
    "    print(\"Calculating forward latency:\\n  \", end=\"\")\n",
    "    %timeit -n 100 module.predict(input_ids, token_type_ids)\n",
    "else:\n",
    "    backend_choice = \"iree_llvmcpu (CPU)\" #@param [ \"iree_vmvx (CPU)\", \"iree_llvmcpu (CPU)\", \"iree_vulkan (GPU/SwiftShader)\" ]\n",
    "    backend_choice = backend_choice.split(\" \")[0]\n",
    "    backend = module_utils.BackendInfo(backend_choice)\n",
    "    compiled_model = backend.compile_from_class(BertModule, [\"predict\"])\n",
    "    t1_stop = time.perf_counter()\n",
    "    print(\"**** Model {} - Total Time: {:.3f}s\".format(modelname, t1_stop - t1_start)) # print performance indicator\n",
    "\n",
    "    print(\"Performing benchmark...\")\n",
    "    print(\"Calculating forward latency:\\n  \", end=\"\")\n",
    "    %timeit -n 100 compiled_model.predict(input_ids, token_type_ids)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cef4e6f",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8373d7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp8yzyoaw9.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp8yzyoaw9.sm/assets\n",
      "2024-05-21 18:11:38.181184: I tensorflow/cc/saved_model/bundle_v2.cc:44] Reading SavedModel from: /tmp/tmp8yzyoaw9.sm\n",
      "2024-05-21 18:11:38.250725: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmp8yzyoaw9.sm\n",
      "2024-05-21 18:11:39.588854: W tensorflow/compiler/mlir/tensorflow/transforms/xla_cluster_formation.cc:81] no entry function is found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model LSTM - Total Time: 14.603s\n",
      "Calculating forward latency:\n",
      "  1.69 ms ± 41.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import iree\n",
    "import numpy as np\n",
    "from iree import runtime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from iree.compiler import tools\n",
    "from benchmark import benchmark_module\n",
    "from tensorflow.keras import backend\n",
    "from iree.tf.support import module_utils\n",
    "from keras_def import KerasLSTM\n",
    "\n",
    "channels_first = True\n",
    "modelname = \"LSTM\"  \n",
    "batch_size = 8\n",
    "hidden_size = 128\n",
    "seq_size = 32\n",
    "input_size = 256\n",
    "\n",
    "t1_start = time.perf_counter()\n",
    "INPUT_SHAPE = (batch_size, seq_size,hidden_size)\n",
    "input = np.random.randn(batch_size, seq_size,hidden_size).astype(np.float32)\n",
    "h0 = np.zeros((batch_size, hidden_size), dtype=np.float32)\n",
    "c0 = np.zeros((batch_size, hidden_size), dtype=np.float32)\n",
    "model = KerasLSTM(input_shape=input.shape[1:], seq_size = seq_size, hidden_size = hidden_size)\n",
    "# Wrap the model in a tf.Module to compile it with IREE.\n",
    "class Module(tf.Module):\n",
    "    def __init__(self):\n",
    "        super(Module, self).__init__()\n",
    "        self.m = model\n",
    "        self.m.predict = lambda x: self.m.call(x, training=False)\n",
    "        self.predict = tf.function(\n",
    "            input_signature=[tf.TensorSpec(INPUT_SHAPE, tf.float32)])(model.predict)\n",
    "\n",
    "binary = iree.compiler.tf.compile_module(\n",
    "        Module(),\n",
    "        target_backends=[\"cuda\"],\n",
    "        exported_names=[\"predict\"])\n",
    "\n",
    "t1_stop = time.perf_counter()\n",
    "print(\"**** Model {} - Total Time: {:.3f}s\".format(modelname, t1_stop - t1_start)) # print performance indicator\n",
    "compiled_model = runtime.load_vm_flatbuffer(binary, driver=\"cuda\")\n",
    "\n",
    "print(\"Calculating forward latency:\\n  \", end=\"\")\n",
    "%timeit -n 100 compiled_model.predict(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a952773c-fbcc-48e5-aa20-49180124fc92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5282355e-5db6-42a6-bd89-735d680a7711",
   "metadata": {},
   "source": [
    "# UFront Test (GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330f0f0c",
   "metadata": {},
   "source": [
    "#### Vision Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb2b7e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tf2onnx.tf_loader:Could not search for non-variable resources. Concrete function internal representation may have changed.\n",
      "2024-05-21 16:06:07.625910: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-05-21 16:06:07.626056: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2024-05-21 16:06:08.152926: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-05-21 16:06:08.153075: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling TOSA model...\n",
      "ResNet18****Ufront->TOSA Time: 2.403s, TOSA->Binary Time: 1.935s, Total Time: 4.337s\n",
      "ResNet18 - 2.878 ± 0.004 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tf2onnx.tf_loader:Could not search for non-variable resources. Concrete function internal representation may have changed.\n",
      "2024-05-21 16:06:27.413748: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-05-21 16:06:27.413900: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2024-05-21 16:06:27.870573: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-05-21 16:06:27.870714: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling TOSA model...\n",
      "MobileNetV3****Ufront->TOSA Time: 2.591s, TOSA->Binary Time: 2.500s, Total Time: 5.091s\n",
      "MobileNetV3 - 1.151 ± 0.003 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tf2onnx.tf_loader:Could not search for non-variable resources. Concrete function internal representation may have changed.\n",
      "2024-05-21 16:06:45.077633: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-05-21 16:06:45.077795: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2024-05-21 16:06:46.021675: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-05-21 16:06:46.021807: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling TOSA model...\n",
      "ResNet50****Ufront->TOSA Time: 5.025s, TOSA->Binary Time: 3.051s, Total Time: 8.076s\n",
      "ResNet50 - 6.045 ± 0.025 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tf2onnx.tf_loader:Could not search for non-variable resources. Concrete function internal representation may have changed.\n",
      "2024-05-21 16:07:06.529522: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-05-21 16:07:06.529687: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2024-05-21 16:07:06.671457: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-05-21 16:07:06.671596: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling TOSA model...\n",
      "SqueezeNet****Ufront->TOSA Time: 0.902s, TOSA->Binary Time: 1.601s, Total Time: 2.503s\n",
      "SqueezeNet - 1.131 ± 0.003 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tf2onnx.tf_loader:Could not search for non-variable resources. Concrete function internal representation may have changed.\n",
      "2024-05-21 16:07:21.089181: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-05-21 16:07:21.089381: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2024-05-21 16:07:21.558486: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-05-21 16:07:21.558631: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling TOSA model...\n",
      "ShuffleNet****Ufront->TOSA Time: 2.285s, TOSA->Binary Time: 1.965s, Total Time: 4.250s\n",
      "ShuffleNet - 2.220 ± 0.000 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tf2onnx.tf_loader:Could not search for non-variable resources. Concrete function internal representation may have changed.\n",
      "2024-05-21 16:07:39.019604: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-05-21 16:07:39.019760: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2024-05-21 16:07:40.088663: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-05-21 16:07:40.088818: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling TOSA model...\n",
      "Inception3****Ufront->TOSA Time: 6.085s, TOSA->Binary Time: 4.092s, Total Time: 10.177s\n",
      "Inception3 - 11.420 ± 0.040 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tf2onnx.tf_loader:Could not search for non-variable resources. Concrete function internal representation may have changed.\n",
      "2024-05-21 16:08:04.820175: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-05-21 16:08:04.820336: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2024-05-21 16:08:06.242510: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-05-21 16:08:06.242697: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling TOSA model...\n",
      "DenseNet****Ufront->TOSA Time: 6.415s, TOSA->Binary Time: 4.439s, Total Time: 10.855s\n",
      "DenseNet - 6.551 ± 0.033 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tf2onnx.tf_loader:Could not search for non-variable resources. Concrete function internal representation may have changed.\n",
      "2024-05-21 16:08:29.261620: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-05-21 16:08:29.261780: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2024-05-21 16:08:34.388363: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-05-21 16:08:34.388528: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling TOSA model...\n",
      "Vit****Ufront->TOSA Time: 23.300s, TOSA->Binary Time: 4.824s, Total Time: 28.124s\n",
      "Vit - 29.000 ± 0.063 ms\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import iree\n",
    "from iree import runtime\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend\n",
    "from iree.tf.support import module_utils\n",
    "from vit_keras import vit\n",
    "from keras_def import SequentialCNN, ConcatenatedCNN, NestedCNN, ShuffleNet, SqueezeNet_11, ResNet18\n",
    "from ufront.keras.model import UFrontKeras\n",
    "import iree.compiler as ireec\n",
    "from benchmark import benchmark_module\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50, ResNet50V2, MobileNetV3Small, DenseNet121, InceptionV3, VGG16\n",
    "channels_first = True\n",
    "GPU = True\n",
    "model_list = {\"ResNet18\":ResNet18, \"MobileNetV3\":MobileNetV3Small, \"ResNet50\":ResNet50, \"SqueezeNet\":SqueezeNet_11, \"ShuffleNet\":ShuffleNet,\n",
    "              \"Inception3\":InceptionV3, \"DenseNet\":DenseNet121, \n",
    "             \"Vit\":vit.vit_b16} \n",
    "\n",
    "\n",
    "INPUT_SHAPE = [1, 3, 224, 224] if channels_first else [1, 224, 224, 3]\n",
    "backend.set_image_data_format('channels_first' if channels_first else 'channels_last')\n",
    "input = np.random.uniform(low=0.0, high=1.0, size=(1, 3, 224, 224) if channels_first else (1, 224, 224, 3)).astype(np.float32)\n",
    "\n",
    "for modelname, Model in model_list.items():\n",
    "    \n",
    "    if modelname == \"Vit\":\n",
    "        base_model = Model(image_size=224, activation='relu', pretrained=False, include_top=True, pretrained_top=False, channel_first=channels_first)\n",
    "    elif modelname == \"SqueezeNet\":\n",
    "        base_model = Model(input_shape=tuple(INPUT_SHAPE[1:]), nb_classes=1000, channel_first=channels_first)\n",
    "    elif modelname == \"ShuffleNet\":\n",
    "        base_model = Model(include_top=True, input_shape=tuple(INPUT_SHAPE[1:]))\n",
    "    elif modelname == \"ResNet18\":\n",
    "        base_model = Model(classes=1000, input_shape=tuple(INPUT_SHAPE[1:]))\n",
    "    else:\n",
    "        base_model = Model(weights=None, include_top=True, input_shape=tuple(INPUT_SHAPE[1:]))\n",
    "        \n",
    "    model_name = base_model.name\n",
    "\n",
    "    transformer = True if model_name.find(\"Transformer\") > 0 or model_name.find(\"vit\") >= 0 else False\n",
    "    t1_start = time.perf_counter()\n",
    "\n",
    "    model = UFrontKeras(base_model, inputs = [input], batch_size = 1, transformer=transformer, pass_weights=True)\n",
    "\n",
    "    if transformer:\n",
    "      last_op = model.get_output_operator()\n",
    "      output = model.umodel().softmax(input=last_op.get_output(0), name=\"softmax_out\")\n",
    "\n",
    "    model.compile(optimizer={\"type\":\"sgd\", \"lr\":\"0.01\", \"momentum\":\"0\", \"nesterov\":\"False\", \"weight_decay\":\"0\"},\n",
    "                        loss='sparse_categorical_crossentropy', metrics=['accuracy', 'sparse_categorical_crossentropy'])\n",
    "    \n",
    "    tosa_ir= model.dump_tosa_ir()\n",
    "    t1_stop = time.perf_counter()\n",
    "    print(\"Compiling TOSA model...\")\n",
    "    binary = ireec.compile_str(tosa_ir,\n",
    "                    target_backends=[\"cuda\"], \n",
    "                    input_type=ireec.InputType.TOSA)\n",
    "\n",
    "    t2_stop = time.perf_counter()\n",
    "    print(modelname + \"****Ufront->TOSA Time: {:.3f}s, TOSA->Binary Time: {:.3f}s, Total Time: {:.3f}s\".format(t1_stop - t1_start, t2_stop - t1_stop, t2_stop - t1_start)) # print performance indicator\n",
    "\n",
    "    module = runtime.load_vm_flatbuffer(binary, driver=\"cuda\")\n",
    "    tms = []\n",
    "    for i in range(10):\n",
    "        ret = benchmark_module(module.vm_module, entry_function=\"forward\", inputs=[\"1x3x224x224xf32=1\"], device=\"cuda\")\n",
    "        tm = ret[0].time\n",
    "        tms.append(float(tm[0:-3]))\n",
    "    print(\"{} - {:.3f} ± {:.3f} ms\".format(modelname, np.mean(tms), np.std(tms)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1e1b2a",
   "metadata": {},
   "source": [
    "#### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e436dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 16:26:18.516202: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/root/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "Could not search for non-variable resources. Concrete function internal representation may have changed.\n",
      "2024-05-21 16:26:24.396774: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-05-21 16:26:24.396970: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2024-05-21 16:26:31.450491: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-05-21 16:26:31.450689: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling TOSA model...\n",
      "Compiling Binary...\n",
      "Bert****Ufront->TOSA Time: 27.892s, TOSA->Binary Time: 4.408s, Total Time: 32.300s\n",
      "3.29 ms ± 41.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "from bert import BertModelLayer\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from ufront.keras.model import UFrontKeras\n",
    "import iree.compiler as ireec\n",
    "from iree import runtime\n",
    "import time\n",
    "\n",
    "l_bert = BertModelLayer(**BertModelLayer.Params(\n",
    "  vocab_size               = 16000,        # embedding params\n",
    "  use_token_type           = True,\n",
    "  use_position_embeddings  = True,\n",
    "  token_type_vocab_size    = 16000,\n",
    "\n",
    "  num_layers               = 12,           # transformer encoder params\n",
    "  hidden_size              = 768,\n",
    "  hidden_dropout           = 0.1,\n",
    "  intermediate_size        = 4*768,\n",
    "  intermediate_activation  = \"gelu\",\n",
    "\n",
    "  adapter_size             = None,         # see arXiv:1902.00751 (adapter-BERT)\n",
    "\n",
    "  shared_layer             = False,        # True for ALBERT (arXiv:1909.11942)\n",
    "  embedding_size           = None,         # None for BERT, wordpiece embedding size for ALBERT\n",
    "  num_heads = 12,\n",
    "  # name                     = \"bert\"        # any other Keras layer params\n",
    "))\n",
    "\n",
    "input_ids = np.array([[31, 51, 99], [15, 5, 0]], dtype='int32')\n",
    "input_mask = np.array([[1, 1, 1], [1, 1, 0]], dtype='int32')\n",
    "token_type_ids = np.array([[0, 0, 1], [0, 1, 0]], dtype='int32')\n",
    "\n",
    "max_seq_len = 3\n",
    "l_input_ids      = keras.layers.Input(shape=(max_seq_len,), dtype='int32')\n",
    "l_token_type_ids = keras.layers.Input(shape=(max_seq_len,), dtype='int32')\n",
    "\n",
    "output = l_bert([l_input_ids, l_token_type_ids])          # [batch_size, max_seq_len, hidden_size]\n",
    "net = keras.Model(inputs=[l_input_ids, l_token_type_ids], outputs=output)\n",
    "\n",
    "t1_start = time.perf_counter()\n",
    "model = UFrontKeras(net, inputs = [input_ids, token_type_ids], batch_size = 1, transformer=True, pass_weights=True)\n",
    "\n",
    "model.compile(optimizer={\"type\":\"sgd\", \"lr\":\"0.01\", \"momentum\":\"0\", \"nesterov\":\"False\", \"weight_decay\":\"0\"},\n",
    "                        loss='sparse_categorical_crossentropy', metrics=['accuracy', 'sparse_categorical_crossentropy'])\n",
    "\n",
    "\n",
    "print(\"Compiling TOSA model...\")\n",
    "tosa_ir= model.dump_tosa_ir()\n",
    "t1_stop = time.perf_counter()\n",
    "\n",
    "print(\"Compiling Binary...\")\n",
    "binary = ireec.compile_str(tosa_ir,\n",
    "                target_backends=[\"cuda\"], \n",
    "                input_type=ireec.InputType.TOSA)\n",
    "t2_stop = time.perf_counter()\n",
    "\n",
    "print(\"Bert****Ufront->TOSA Time: {:.3f}s, TOSA->Binary Time: {:.3f}s, Total Time: {:.3f}s\".format(t1_stop - t1_start, t2_stop - t1_stop, t2_stop - t1_start)) # print performance indicator\n",
    "module = runtime.load_vm_flatbuffer(binary, driver=\"cuda\")\n",
    "%timeit -n 100 module.forward(input_ids, token_type_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5e7512",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee35b09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 16:27:03.095086: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/root/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "Could not search for non-variable resources. Concrete function internal representation may have changed.\n",
      "2024-05-22 16:27:06.569871: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-05-22 16:27:06.570062: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2024-05-22 16:27:08.334241: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-05-22 16:27:08.334436: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM****Ufront->TOSA Time: 6.917s, TOSA->Binary Time: 1.008s, Total Time: 7.925s\n",
      "1.61 ms ± 28.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "import iree.compiler as ireec\n",
    "from iree import runtime\n",
    "import time\n",
    "import numpy as np\n",
    "from ufront.keras.model import UFrontKeras\n",
    "from keras_def import KerasLSTM\n",
    "batch_size = 8\n",
    "hidden_size = 128\n",
    "seq_size = 32\n",
    "input_size = 256\n",
    "input = np.random.randn(batch_size, seq_size,hidden_size).astype(np.float32)\n",
    "h0 = np.zeros((batch_size, hidden_size), dtype=np.float32)\n",
    "c0 = np.zeros((batch_size, hidden_size), dtype=np.float32)\n",
    "t1_start = time.perf_counter()\n",
    "lstm = KerasLSTM(input_shape=input.shape[1:], seq_size = seq_size, hidden_size = hidden_size)\n",
    "model = UFrontKeras(lstm, inputs = [input], batch_size = 1, pass_weights=True)\n",
    "output_tensors = model(inputs = [input])\n",
    "\n",
    "#This will trigger model compilation, i.e., convert Rust computation graph to a unified high-level IR and lower it to TOSA IR\n",
    "model.compile(optimizer={\"type\":\"sgd\", \"lr\":\"0.01\", \"momentum\":\"0\", \"nesterov\":\"False\", \"weight_decay\":\"0\"},\n",
    "                      loss='sparse_categorical_crossentropy', metrics=['accuracy', 'sparse_categorical_crossentropy'])\n",
    "\n",
    "\n",
    "# modelir= model.dump_ir()\n",
    "# print(modelir)\n",
    "\n",
    "tosa_ir = model.dump_tosa_ir()\n",
    "t1_stop = time.perf_counter()\n",
    "binary = ireec.compile_str(tosa_ir,\n",
    "                target_backends=[\"cuda\"], \n",
    "                input_type=ireec.InputType.TOSA)\n",
    "t2_stop = time.perf_counter()\n",
    "print(\"LSTM****Ufront->TOSA Time: {:.3f}s, TOSA->Binary Time: {:.3f}s, Total Time: {:.3f}s\".format(t1_stop - t1_start, t2_stop - t1_stop, t2_stop - t1_start)) # print performance indicator\n",
    "\n",
    "module = runtime.load_vm_flatbuffer(binary, driver=\"cuda\")\n",
    "%timeit -n 100 module.forward(input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
