{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-07-19T06:58:04.161225Z","iopub.status.busy":"2023-07-19T06:58:04.160089Z","iopub.status.idle":"2023-07-19T06:58:07.505490Z","shell.execute_reply":"2023-07-19T06:58:07.504103Z","shell.execute_reply.started":"2023-07-19T06:58:04.161168Z"},"trusted":true},"outputs":[],"source":["import torch,os,random\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from typing import Tuple\n","from PIL import Image\n","from torchvision import transforms\n","from torch.utils import data\n","from functools import partial\n","from torchvision.models import resnet18, resnet50, squeezenet1_1, regnet_x_32gf, maxvit_t, shufflenet_v2_x1_5, inception_v3, mobilenet_v3_small, efficientnet_v2_s, densenet121, convnext_small\n","import tqdm"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T06:58:42.340750Z","iopub.status.busy":"2023-07-19T06:58:42.339960Z","iopub.status.idle":"2023-07-19T06:58:43.552864Z","shell.execute_reply":"2023-07-19T06:58:43.551573Z","shell.execute_reply.started":"2023-07-19T06:58:42.340693Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--2023-07-19 06:58:43--  https://raw.githubusercontent.com/raghakot/keras-vis/master/resources/imagenet_class_index.json\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 35363 (35K) [text/plain]\n","Saving to: ‘imagenet_class_index.json’\n","\n","imagenet_class_inde 100%[===================>]  34.53K  --.-KB/s    in 0.004s  \n","\n","2023-07-19 06:58:43 (9.36 MB/s) - ‘imagenet_class_index.json’ saved [35363/35363]\n","\n"]}],"source":["root = \"/root/data/\" #set to the path of imagenet-1k validation set, which contains a folder named 'imagenet1kvalid'\n","!wget https://raw.githubusercontent.com/raghakot/keras-vis/master/resources/imagenet_class_index.json"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T08:12:00.249673Z","iopub.status.busy":"2023-07-19T08:12:00.248487Z","iopub.status.idle":"2023-07-19T08:12:00.269494Z","shell.execute_reply":"2023-07-19T08:12:00.267987Z","shell.execute_reply.started":"2023-07-19T08:12:00.249626Z"},"trusted":true},"outputs":[],"source":["import os\n","from torch.utils.data import Dataset\n","from PIL import Image\n","import json\n","syn_to_class = {}\n","with open(os.path.join(root, \"imagenet_class_index.json\"), \"rb\") as f:\n","    json_file = json.load(f)\n","    for class_id, v in json_file.items():\n","        syn_to_class[class_id] = v[1]\n","                \n","def get_class_name(entry):        \n","    target = syn_to_class[int(entry)]\n","    return target\n","        \n","class ImageNetKaggle(Dataset):\n","    def __init__(self, root, transform=None):\n","        self.samples = []\n","        self.targets = []\n","        self.transform = transform\n","        samples_dir = os.path.join(root, \"imagenet1kvalid\")\n","        for entry in os.listdir(samples_dir):\n","                sample_path = os.path.join(samples_dir, entry)\n","                for file in os.listdir(sample_path):                    \n","                    self.samples.append(os.path.join(sample_path, file))\n","                    self.targets.append(int(entry))\n","                \n","    def __len__(self):\n","            return len(self.samples)\n","        \n","    def __getitem__(self, idx):\n","            x = Image.open(self.samples[idx]).convert(\"RGB\")\n","            if self.transform:\n","                x = self.transform(x)\n","            return x, self.targets[idx]"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T06:58:50.719711Z","iopub.status.busy":"2023-07-19T06:58:50.718981Z","iopub.status.idle":"2023-07-19T06:59:03.495219Z","shell.execute_reply":"2023-07-19T06:59:03.494044Z","shell.execute_reply.started":"2023-07-19T06:58:50.719671Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader\n","from torchvision import transforms\n","import torch\n","import torchvision\n","from tqdm import tqdm\n","mean = (0.485, 0.456, 0.406)\n","std = (0.229, 0.224, 0.225)\n","val_transform = transforms.Compose(\n","            [\n","                transforms.Resize(256),\n","                transforms.CenterCrop(224),\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean, std),\n","            ]\n","        )\n","dataset = ImageNetKaggle(root, val_transform)\n","dataloader = DataLoader(\n","            dataset,\n","            batch_size=64, # may need to reduce this depending on your GPU \n","            num_workers=8, # may need to reduce this depending on your num of CPUs and RAM\n","            shuffle=False,\n","            drop_last=False,\n","            pin_memory=True\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### Download and install UFront package"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T07:35:46.594826Z","iopub.status.busy":"2023-07-19T07:35:46.594155Z","iopub.status.idle":"2023-07-19T07:36:08.005752Z","shell.execute_reply":"2023-07-19T07:36:08.004459Z","shell.execute_reply.started":"2023-07-19T07:35:46.594780Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--2023-07-19 07:35:47--  https://anonymous.4open.science/r/anonyufront-2B3E/release/ufront-0.1.1-cp37-cp37m-manylinux_2_28_x86_64.whl\n","Resolving anonymous.4open.science (anonymous.4open.science)... 104.21.18.195, 172.67.183.76, 2606:4700:3035::ac43:b74c, ...\n","Connecting to anonymous.4open.science (anonymous.4open.science)|104.21.18.195|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: /api/repo/anonyufront-2B3E/file/release/ufront-0.1.1-cp37-cp37m-manylinux_2_28_x86_64.whl [following]\n","--2023-07-19 07:35:48--  https://anonymous.4open.science/api/repo/anonyufront-2B3E/file/release/ufront-0.1.1-cp37-cp37m-manylinux_2_28_x86_64.whl\n","Reusing existing connection to anonymous.4open.science:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 60623698 (58M)\n","Saving to: ‘ufront-0.1.1-cp37-cp37m-manylinux_2_28_x86_64.whl’\n","\n","ufront-0.1.1-cp37-c 100%[===================>]  57.81M   111MB/s    in 0.5s    \n","\n","2023-07-19 07:36:07 (111 MB/s) - ‘ufront-0.1.1-cp37-cp37m-manylinux_2_28_x86_64.whl’ saved [60623698/60623698]\n","\n"]}],"source":["# You may execute !python --version and install the following ufront package based on your python version\n","\n","# For Python 3.7\n","!wget https://anonymous.4open.science/r/anonyufront-2B3E/release/ufront-0.1.1-cp37-cp37m-manylinux_2_28_x86_64.whl\n","\n","# For Python 3.8\n","# !wget https://anonymous.4open.science/r/anonyufront-2B3E/release/ufront-0.1.1-cp38-cp38-manylinux_2_28_x86_64.whl\n","\n","# For Python 3.9\n","# !wget https://anonymous.4open.science/r/anonyufront-2B3E/release/ufront-0.1.1-cp39-cp39-manylinux_2_28_x86_64.whl\n","\n","# For Python 3.10\n","# !wget https://anonymous.4open.science/r/anonyufront-2B3E/release/ufront-0.1.1-cp310-cp310-manylinux_2_28_x86_64.whl\n"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T07:36:23.630292Z","iopub.status.busy":"2023-07-19T07:36:23.629711Z","iopub.status.idle":"2023-07-19T07:36:39.012255Z","shell.execute_reply":"2023-07-19T07:36:39.010902Z","shell.execute_reply.started":"2023-07-19T07:36:23.630228Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing ./ufront-0.1.1-cp37-cp37m-manylinux_2_28_x86_64.whl\n","Requirement already satisfied: onnx in /opt/conda/lib/python3.7/site-packages (from ufront==0.1.1) (1.13.1)\n","Collecting tf2onnx\n","  Downloading tf2onnx-1.14.0-py3-none-any.whl (451 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.2/451.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: protobuf<4,>=3.20.2 in /opt/conda/lib/python3.7/site-packages (from onnx->ufront==0.1.1) (3.20.3)\n","Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.7/site-packages (from onnx->ufront==0.1.1) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.6.2.1 in /opt/conda/lib/python3.7/site-packages (from onnx->ufront==0.1.1) (4.4.0)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from tf2onnx->ufront==0.1.1) (2.28.2)\n","Collecting flatbuffers<3.0,>=1.12\n","  Downloading flatbuffers-2.0.7-py2.py3-none-any.whl (26 kB)\n","Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from tf2onnx->ufront==0.1.1) (1.16.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->tf2onnx->ufront==0.1.1) (1.26.14)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->tf2onnx->ufront==0.1.1) (3.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->tf2onnx->ufront==0.1.1) (2.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->tf2onnx->ufront==0.1.1) (2022.12.7)\n","Installing collected packages: flatbuffers, tf2onnx, ufront\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 23.1.21\n","    Uninstalling flatbuffers-23.1.21:\n","      Successfully uninstalled flatbuffers-23.1.21\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n","tensorflow-transform 1.12.0 requires pyarrow<7,>=6, but you have pyarrow 5.0.0 which is incompatible.\n","tensorflow-serving-api 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed flatbuffers-2.0.7 tf2onnx-1.14.0 ufront-0.1.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install ufront-0.1.1-cp37-cp37m-manylinux_2_28_x86_64.whl\n","\n","# !pip install ufront-0.1.1-cp38-cp38-manylinux_2_28_x86_64.whl \n","# !pip install ufront-0.1.1-cp39-cp39-manylinux_2_28_x86_64.whl\n","# !pip install ufront-0.1.1-cp310-cp310-manylinux_2_28_x86_64.whl"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T07:26:33.654084Z","iopub.status.busy":"2023-07-19T07:26:33.653016Z","iopub.status.idle":"2023-07-19T07:26:55.850920Z","shell.execute_reply":"2023-07-19T07:26:55.848753Z","shell.execute_reply.started":"2023-07-19T07:26:33.653991Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in links: https://openxla.github.io/iree/pip-release-links.html\n","Collecting iree-compiler==20230326.470\n","  Downloading https://github.com/openxla/iree/releases/download/candidate-20230326.470/iree_compiler-20230326.470-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hCollecting iree-runtime==20230326.470\n","  Downloading https://github.com/openxla/iree/releases/download/candidate-20230326.470/iree_runtime-20230326.470-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from iree-compiler==20230326.470) (1.21.6)\n","Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from iree-compiler==20230326.470) (6.0)\n","Installing collected packages: iree-runtime, iree-compiler\n","Successfully installed iree-compiler-20230326.470 iree-runtime-20230326.470\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["# Install compiler backend and runtime\n","!pip install iree-compiler==20230512.517 iree-runtime==20230512.517 -f https://openxla.github.io/iree/pip-release-links.html"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Compile the models and run on CPU/GPU"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T08:13:39.774016Z","iopub.status.busy":"2023-07-19T08:13:39.773188Z","iopub.status.idle":"2023-07-19T08:13:39.785681Z","shell.execute_reply":"2023-07-19T08:13:39.784551Z","shell.execute_reply.started":"2023-07-19T08:13:39.773952Z"},"trusted":true},"outputs":[],"source":["from ufront.pytorch.model import UFrontTorch \n","import iree.compiler as ireec\n","from iree.compiler import tools\n","from iree import runtime\n","# !pip install onnxsim \n","\n","def compile_with_ufront(net, GPU, dataloader):\n","    for x, y in dataloader:\n","        break\n","    net.eval()\n","    indata = x.numpy()\n","    model = UFrontTorch(net, batch_size=indata.shape[0], pass_weights=True) # convert torch model to ufront model\n","    #This will trigger Rust frontend for actual model conversion and graph building\n","    #operators can also be managed by python side (each operator here corresponding to an operator in the Rust computation graph)\n","    output_tensors = model(inputs = [indata])\n","\n","    #The output of the model (forward pass have not been triggered at the moment!)\n","    # if model.model.__class__.__name__ not in [\"MaxVit\", \"SwinTransformer\", \"VisionTransformer\", \"MultiHeadAttention\"]:\n","    output = model.softmax(input=output_tensors[0], name=\"softmax_out\")\n","\n","    #This will trigger model compilation, i.e., convert Rust computation graph to a unified high-level IR and lower it to TOSA IR\n","    model.compile(optimizer={\"type\":\"sgd\", \"lr\":\"0.01\", \"momentum\":\"0\", \"nesterov\":\"False\", \"weight_decay\":\"0\"},\n","                        loss='sparse_categorical_crossentropy', metrics=['accuracy', 'sparse_categorical_crossentropy'])\n","\n","    modelir = model.dump_ir()\n","\n","    tosa_ir= model.dump_tosa_ir()\n","\n","    print(\"Compiling TOSA model...\")\n","    if GPU:\n","        binary = ireec.compile_str(tosa_ir,\n","                        target_backends=[\"cuda\"], \n","                        input_type=ireec.InputType.TOSA)\n","        module = runtime.load_vm_flatbuffer(binary, driver=\"cuda\")\n","    else:\n","        binary = ireec.compile_str(tosa_ir,\n","                        target_backends=[\"llvm-cpu\"], \n","                        input_type=ireec.InputType.TOSA)\n","        module = runtime.load_vm_flatbuffer(binary,backend=\"llvm-cpu\") \n","    return module"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T08:23:48.612213Z","iopub.status.busy":"2023-07-19T08:23:48.611783Z","iopub.status.idle":"2023-07-19T08:23:48.621582Z","shell.execute_reply":"2023-07-19T08:23:48.620404Z","shell.execute_reply.started":"2023-07-19T08:23:48.612175Z"},"trusted":true},"outputs":[],"source":["def get_ufront_accuracy(module, dataloader):\n","    correct = 0.0\n","    total = 0.0\n","    batch_size = 0\n","    for x, y in tqdm(dataloader):\n","        if batch_size == 0:\n","            batch_size = x.shape[0]\n","        elif x.shape[0] < batch_size:\n","            print(\"Ignore last batch!\") #dynamic batch size is currently not supported!\n","            break\n","        y_pred = module.forward(x.numpy()).to_host()\n","        correct += (y_pred.argmax(axis=1) == y.numpy()).sum().item()\n","        total += len(y)\n","    return correct / total"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T08:25:19.373841Z","iopub.status.busy":"2023-07-19T08:25:19.373374Z","iopub.status.idle":"2023-07-19T08:32:05.276245Z","shell.execute_reply":"2023-07-19T08:32:05.274878Z","shell.execute_reply.started":"2023-07-19T08:25:19.373802Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Compiling TOSA model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 780/782 [06:05<00:00,  6.38it/s]"]},{"name":"stdout","output_type":"stream","text":["Ignore last batch!\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 781/782 [06:05<00:00,  2.14it/s]\n"]},{"data":{"text/plain":["0.6700544174135723"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["net = mobilenet_v3_small(weights=\"DEFAULT\", dropout=0.0)\n","module = compile_with_ufront(net, True, dataloader)\n","get_ufront_accuracy(module, dataloader)"]},{"cell_type":"code","execution_count":77,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T08:35:14.958717Z","iopub.status.busy":"2023-07-19T08:35:14.958305Z","iopub.status.idle":"2023-07-19T08:42:00.036335Z","shell.execute_reply":"2023-07-19T08:42:00.035093Z","shell.execute_reply.started":"2023-07-19T08:35:14.958680Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Compiling TOSA model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 781/782 [06:09<00:00,  6.40it/s]"]},{"name":"stdout","output_type":"stream","text":["Ignore last batch!\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 781/782 [06:10<00:00,  2.11it/s]\n"]},{"data":{"text/plain":["0.7178697183098591"]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"source":["net = shufflenet_v2_x1_5(weights=\"DEFAULT\")\n","module = compile_with_ufront(net, True, dataloader)\n","get_ufront_accuracy(module, dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T08:42:47.852895Z","iopub.status.busy":"2023-07-19T08:42:47.851807Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/squeezenet1_1-b8a52dc0.pth\" to /root/.cache/torch/hub/checkpoints/squeezenet1_1-b8a52dc0.pth\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"586c78e877e94994a6bd883155e3c3fa","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0.00/4.73M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Compiling TOSA model...\n"]},{"name":"stderr","output_type":"stream","text":[" 58%|█████▊    | 451/782 [03:39<02:23,  2.30it/s]"]}],"source":["net = squeezenet1_1(weights=\"DEFAULT\")\n","module = compile_with_ufront(net, True, dataloader)\n","get_ufront_accuracy(module, dataloader)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Compiling TOSA model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 781/782 [11:30<00:00,  1.13it/s]"]},{"name":"stdout","output_type":"stream","text":["Ignore last batch!\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"data":{"text/plain":["0.6934218950064021"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["net = resnet18(weights=\"DEFAULT\")\n","module = compile_with_ufront(net, True, dataloader)\n","get_ufront_accuracy(module, dataloader)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c70d1d83c66847939a332ca29ecc3907","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0.00/97.8M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Compiling TOSA model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 781/782 [16:19<00:01,  1.25s/it]"]},{"name":"stdout","output_type":"stream","text":["Ignore last batch!\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"data":{"text/plain":["0.7924935979513444"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["net = resnet50(weights=\"DEFAULT\")\n","module = compile_with_ufront(net, True, dataloader)\n","get_ufront_accuracy(module, dataloader)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Compiling TOSA model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 781/782 [15:12<00:01,  1.17s/it]"]},{"name":"stdout","output_type":"stream","text":["Ignore last batch!\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"data":{"text/plain":["0.7362556017925737"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["net = densenet121(weights=\"DEFAULT\")\n","module = compile_with_ufront(net, True, dataloader)\n","get_ufront_accuracy(module, dataloader)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Compiling TOSA model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 781/782 [18:34<00:01,  1.43s/it]"]},{"name":"stdout","output_type":"stream","text":["Ignore last batch!\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"data":{"text/plain":["0.6997439180537772"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["net = inception_v3(weights=\"DEFAULT\") \n","module = compile_with_ufront(net, True, dataloader)\n","get_ufront_accuracy(module, dataloader) #low performance than official reported, to fix this, the image size need to resize to 299 x 299, instead of standard 224 x 224"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/root/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"name":"stdout","output_type":"stream","text":["Compiling TOSA model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 781/782 [1:01:45<00:04,  4.74s/it]"]},{"name":"stdout","output_type":"stream","text":["Ignore last batch!\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"data":{"text/plain":["0.8051976632522407"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["import torchvision.models as models\n","net = models.vision_transformer.vit_b_16(weights=\"DEFAULT\")\n","module = compile_with_ufront(net, True, dataloader)\n","get_ufront_accuracy(module, dataloader)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Compiling TOSA model...\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 781/782 [37:03<00:02,  2.85s/it]"]},{"name":"stdout","output_type":"stream","text":["Ignore last batch!\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"data":{"text/plain":["0.7694462227912933"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["#fix low performance of inception3\n","val_transform = transforms.Compose(\n","            [\n","                transforms.Resize(299),\n","                transforms.CenterCrop(299), #299 instead of 224, see this: https://github.com/IntelLabs/distiller/issues/422\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean, std),\n","            ]\n","        )\n","dataset = ImageNetKaggle(root, val_transform)\n","dataloader = DataLoader(\n","            dataset,\n","            batch_size=64, # may need to reduce this depending on your GPU \n","            num_workers=8, # may need to reduce this depending on your num of CPUs and RAM\n","            shuffle=False,\n","            drop_last=False,\n","            pin_memory=True\n","        )\n","net = inception_v3(weights=\"DEFAULT\") \n","module = compile_with_ufront(net, True, dataloader)\n","get_ufront_accuracy(module, dataloader)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":4}
