{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db63d783-79ed-4f61-b064-eabc0c958fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import time\n",
    "import torch\n",
    "from torchvision.models import resnet18, resnet50, squeezenet1_1, regnet_x_32gf, maxvit_t, shufflenet_v2_x1_5, inception_v3, mobilenet_v3_small, efficientnet_v2_s, densenet121, convnext_small\n",
    "import torchvision.models as models\n",
    "from ufront.pytorch.model import UFrontTorch\n",
    "import argparse\n",
    "import ctypes\n",
    "from iree.compiler import tools\n",
    "from iree import runtime\n",
    "import iree.runtime as ireert\n",
    "import iree.compiler as ireec\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import iree.runtime as ireert\n",
    "import iree.compiler as ireec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e878ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install iree-compiler==20230512.517 iree-runtime==20230512.517 -f https://openxla.github.io/iree/pip-release-links.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c058395c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV3****Ufront->TOSA Time: 0.260s, TOSA->Binary Time: 6.524s, Total Time: 6.784s\n",
      "ShuffleNetV2****Ufront->TOSA Time: 0.373s, TOSA->Binary Time: 4.092s, Total Time: 4.465s\n",
      "ResNet18****Ufront->TOSA Time: 0.410s, TOSA->Binary Time: 2.868s, Total Time: 3.278s\n",
      "ResNet50****Ufront->TOSA Time: 0.904s, TOSA->Binary Time: 6.228s, Total Time: 7.132s\n",
      "SqueezeNet****Ufront->TOSA Time: 0.076s, TOSA->Binary Time: 3.409s, Total Time: 3.485s\n",
      "DenseNet121****Ufront->TOSA Time: 1.260s, TOSA->Binary Time: 17.486s, Total Time: 18.746s\n",
      "InceptionV3****Ufront->TOSA Time: 1.103s, TOSA->Binary Time: 7.922s, Total Time: 9.025s\n",
      "ViT_B16****Ufront->TOSA Time: 2.637s, TOSA->Binary Time: 5.656s, Total Time: 8.293s\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "input = torch.ones((batch_size, 3, 224, 224), dtype=torch.float32)\n",
    "\n",
    "model_list = {\"MobileNetV3\":mobilenet_v3_small(pretrained=False), \"ShuffleNetV2\":shufflenet_v2_x1_5(pretrained=False),\n",
    "            \"ResNet18\":resnet18(pretrained=False), \"ResNet50\":resnet50(pretrained=False), \"SqueezeNet\":squeezenet1_1(pretrained=False),\n",
    "            \"DenseNet121\":densenet121(pretrained=False), \"InceptionV3\":inception_v3(pretrained=False), \"ViT_B16\":models.vision_transformer.vit_b_16(weights=False, dropout=0.1)}\n",
    "\n",
    "for modelname, net in model_list.items():\n",
    "    # blockPrint()\n",
    "    net.train(False) \n",
    "\n",
    "    t1_start = time.perf_counter()\n",
    "    model = UFrontTorch(net, batch_size=batch_size, pass_weights=True) # convert torch model to ufront model\n",
    "    #This will trigger Rust frontend for actual model conversion and graph building\n",
    "    #operators can also be managed by python side (each operator here corresponding to an operator in the Rust computation graph)\n",
    "    output_tensors = model(inputs = [input])\n",
    "\n",
    "    #The output of the model (forward pass have not been triggered at the moment!)\n",
    "    if model.model.__class__.__name__ not in [\"MaxVit\", \"SwinTransformer\", \"VisionTransformer\", \"MultiHeadAttention\"]:\n",
    "        output = model.softmax(input=output_tensors[0], name=\"softmax_out\")\n",
    "\n",
    "    #This will trigger model compilation, i.e., convert Rust computation graph to a unified high-level IR and lower it to TOSA IR\n",
    "    model.compile(optimizer={\"type\":\"sgd\", \"lr\":\"0.01\", \"momentum\":\"0\", \"nesterov\":\"False\", \"weight_decay\":\"0\"},\n",
    "                        loss='sparse_categorical_crossentropy', metrics=['accuracy', 'sparse_categorical_crossentropy'])\n",
    "    tosa_ir= model.dump_tosa_ir()\n",
    "\n",
    "    t1_stop = time.perf_counter()\n",
    "\n",
    "    # print(\"Compiling TOSA model...\")\n",
    "    compiled_module = ireec.compile_str(tosa_ir,\n",
    "                        target_backends=[\"llvm-cpu\"],\n",
    "                        input_type=ireec.InputType.TOSA)\n",
    "\n",
    "    t2_stop = time.perf_counter()\n",
    "\n",
    "    print(modelname + \"****Ufront->TOSA Time: {:.3f}s, TOSA->Binary Time: {:.3f}s, Total Time: {:.3f}s\".format(t1_stop - t1_start, t2_stop - t1_stop, t2_stop - t1_start)) # print performance indicator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d456434d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/root/anaconda3/lib/python3.9/site-packages/torchvision/models/inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV3****Ufront->TOSA Time: 0.356s, TOSA->Binary Time: 6.222s, Total Time: 6.577s\n",
      "ShuffleNetV2****Ufront->TOSA Time: 0.374s, TOSA->Binary Time: 3.782s, Total Time: 4.156s\n",
      "ResNet18****Ufront->TOSA Time: 0.419s, TOSA->Binary Time: 2.739s, Total Time: 3.158s\n",
      "ResNet50****Ufront->TOSA Time: 0.940s, TOSA->Binary Time: 5.989s, Total Time: 6.929s\n",
      "SqueezeNet****Ufront->TOSA Time: 0.079s, TOSA->Binary Time: 3.159s, Total Time: 3.239s\n",
      "DenseNet121****Ufront->TOSA Time: 1.194s, TOSA->Binary Time: 16.150s, Total Time: 17.344s\n",
      "InceptionV3****Ufront->TOSA Time: 1.130s, TOSA->Binary Time: 7.642s, Total Time: 8.772s\n",
      "ViT_B16****Ufront->TOSA Time: 2.725s, TOSA->Binary Time: 5.781s, Total Time: 8.506s\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "input = torch.ones((batch_size, 3, 224, 224), dtype=torch.float32)\n",
    "\n",
    "model_list = {\"MobileNetV3\":mobilenet_v3_small(pretrained=False), \"ShuffleNetV2\":shufflenet_v2_x1_5(pretrained=False),\n",
    "            \"ResNet18\":resnet18(pretrained=False), \"ResNet50\":resnet50(pretrained=False), \"SqueezeNet\":squeezenet1_1(pretrained=False),\n",
    "            \"DenseNet121\":densenet121(pretrained=False), \"InceptionV3\":inception_v3(pretrained=False), \"ViT_B16\":models.vision_transformer.vit_b_16(weights=False, dropout=0.1)}\n",
    "\n",
    "for modelname, net in model_list.items():\n",
    "    # blockPrint()\n",
    "    net.train(False) \n",
    "\n",
    "    t1_start = time.perf_counter()\n",
    "    model = UFrontTorch(net, batch_size=batch_size, pass_weights=True) # convert torch model to ufront model\n",
    "    #This will trigger Rust frontend for actual model conversion and graph building\n",
    "    #operators can also be managed by python side (each operator here corresponding to an operator in the Rust computation graph)\n",
    "    output_tensors = model(inputs = [input])\n",
    "\n",
    "    #The output of the model (forward pass have not been triggered at the moment!)\n",
    "    if model.model.__class__.__name__ not in [\"MaxVit\", \"SwinTransformer\", \"VisionTransformer\", \"MultiHeadAttention\"]:\n",
    "        output = model.softmax(input=output_tensors[0], name=\"softmax_out\")\n",
    "\n",
    "    #This will trigger model compilation, i.e., convert Rust computation graph to a unified high-level IR and lower it to TOSA IR\n",
    "    model.compile(optimizer={\"type\":\"sgd\", \"lr\":\"0.01\", \"momentum\":\"0\", \"nesterov\":\"False\", \"weight_decay\":\"0\"},\n",
    "                        loss='sparse_categorical_crossentropy', metrics=['accuracy', 'sparse_categorical_crossentropy'])\n",
    "    tosa_ir= model.dump_tosa_ir()\n",
    "\n",
    "    t1_stop = time.perf_counter()\n",
    "\n",
    "    # print(\"Compiling TOSA model...\")\n",
    "    compiled_module = ireec.compile_str(tosa_ir,\n",
    "                        target_backends=[\"llvm-cpu\"],\n",
    "                        input_type=ireec.InputType.TOSA)\n",
    "\n",
    "    t2_stop = time.perf_counter()\n",
    "\n",
    "    print(modelname + \"****Ufront->TOSA Time: {:.3f}s, TOSA->Binary Time: {:.3f}s, Total Time: {:.3f}s\".format(t1_stop - t1_start, t2_stop - t1_stop, t2_stop - t1_start)) # print performance indicator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc98a669-645b-4206-94f1-a544acb0bfc6",
   "metadata": {},
   "source": [
    "# Compile & Run Pytorch BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5c14b5d-ae7e-4064-9425-eafaff1b4c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling TOSA model...\n",
      "785802350\n",
      "Compiling Binary...\n",
      "Bert****Ufront->TOSA Time: 2.970s, TOSA->Binary Time: 5.258s, Total Time: 8.227s\n"
     ]
    }
   ],
   "source": [
    "# import torch, torchtext\n",
    "from ufront.pytorch.model import UFrontTorch \n",
    "import iree.compiler as ireec\n",
    "from iree import runtime\n",
    "from torch_bert import BertModel, BertConfig\n",
    "import torch\n",
    "import time\n",
    "GPU = True\n",
    "input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n",
    "input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n",
    "token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])\n",
    "\n",
    "config = BertConfig(vocab_size_or_config_json_file=16000, hidden_size=768,\n",
    "    num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n",
    "\n",
    "net = BertModel(config=config)\n",
    "net.eval()\n",
    "\n",
    "t1_start = time.perf_counter()\n",
    "model = UFrontTorch(net, batch_size=1, pass_weights=True) # convert torch model to ufront model\n",
    "#This will trigger Rust frontend for actual model conversion and graph building\n",
    "#operators can also be managed by python side (each operator here corresponding to an operator in the Rust computation graph)\n",
    "output_tensors = model(inputs = [input_ids, token_type_ids, input_mask])\n",
    "\n",
    "#This will trigger model compilation, i.e., convert Rust computation graph to a unified high-level IR and lower it to TOSA IR\n",
    "model.compile(optimizer={\"type\":\"sgd\", \"lr\":\"0.01\", \"momentum\":\"0\", \"nesterov\":\"False\", \"weight_decay\":\"0\"},\n",
    "                    loss='sparse_categorical_crossentropy', metrics=['accuracy', 'sparse_categorical_crossentropy'])\n",
    "\n",
    "\n",
    "print(\"Compiling TOSA model...\")\n",
    "tosa_ir= model.dump_tosa_ir()\n",
    "t1_stop = time.perf_counter()\n",
    "\n",
    "print(len(tosa_ir))\n",
    "\n",
    "print(\"Compiling Binary...\")\n",
    "\n",
    "if GPU:\n",
    "    binary = ireec.compile_str(tosa_ir,\n",
    "                    target_backends=[\"cuda\"], \n",
    "                    input_type=ireec.InputType.TOSA)\n",
    "    module = runtime.load_vm_flatbuffer(binary, driver=\"cuda\")\n",
    "else:\n",
    "    binary = ireec.compile_str(tosa_ir,\n",
    "                    target_backends=[\"llvm-cpu\"], \n",
    "                    input_type=ireec.InputType.TOSA)\n",
    "    module = runtime.load_vm_flatbuffer(binary,backend=\"llvm-cpu\") \n",
    "\n",
    "t2_stop = time.perf_counter()\n",
    "\n",
    "print(\"Bert****Ufront->TOSA Time: {:.3f}s, TOSA->Binary Time: {:.3f}s, Total Time: {:.3f}s\".format(t1_stop - t1_start, t2_stop - t1_stop, t2_stop - t1_start)) # print performance indicator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f63cf4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.32 ms ± 69.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 100 module.forward(input_ids, token_type_ids, input_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f37aa3-1339-4777-84b7-fbab791f66d6",
   "metadata": {},
   "source": [
    "# Compile & Run ONNX BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "749af7b4-86d4-4c88-99ee-fd3503c6a44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.9/site-packages/torch/onnx/utils.py:799: UserWarning: It is recommended that constant folding be turned off ('do_constant_folding=False') when exporting the model in training-amenable mode, i.e. with 'training=TrainingMode.TRAIN' or 'training=TrainingMode.PRESERVE' (when model is in training mode). Otherwise, some learnable model parameters may not translate correctly in the exported ONNX model because constant folding mutates model parameters. Please consider turning off constant folding or setting the training=TrainingMode.EVAL.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:923: UserWarning: Warning: ONNX export of embedding with padding_idx >= 0 for training mode. ONNX does not support not updating the embedding vector at padding_idx during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling TOSA model...\n",
      "782623906\n",
      "Compiling Binary...\n",
      "Bert****Ufront->TOSA Time: 19.005s, TOSA->Binary Time: 5.031s, Total Time: 24.036s\n"
     ]
    }
   ],
   "source": [
    "# import torch, torchtext\n",
    "from ufront.pytorch.model import UFrontTorch \n",
    "import iree.compiler as ireec\n",
    "from iree import runtime\n",
    "from torch_bert import BertModel, BertConfig\n",
    "import torch\n",
    "import time\n",
    "from ufront.onnx.model import ONNXModel, ONNXModelKeras, UFrontONNX\n",
    "from torch.onnx import TrainingMode\n",
    "import onnx\n",
    "import io\n",
    "GPU = True\n",
    "input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n",
    "input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n",
    "token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])\n",
    "\n",
    "config = BertConfig(vocab_size_or_config_json_file=16000, hidden_size=768,\n",
    "    num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n",
    "\n",
    "net = BertModel(config=config)\n",
    "net.eval()\n",
    "t1_start = time.perf_counter()\n",
    "\n",
    "f = io.BytesIO()\n",
    "model_name = net.__class__.__name__ \n",
    "torch.onnx.export(model=net, args=(input_ids, input_mask, token_type_ids), f=f, export_params=True, #do_constant_folding=True,\n",
    "                    training=TrainingMode.EVAL if model_name==\"Inception3\" else TrainingMode.TRAINING, opset_version=17)\n",
    "onnx_model = onnx.load_model_from_string(f.getvalue())\n",
    "\n",
    "# transformer = True if model_name in [\"MaxVit\", \"SwinTransformer\", \"VisionTransformer\", \"MultiHeadAttention\"] else False\n",
    "model = UFrontONNX(onnx_model=onnx_model, batch_size=1, simplify=True, pass_weights=True, transformer=True)\n",
    "\n",
    "\n",
    "#operators can also be managed by python side (each operator here corresponding to an operator in the Rust computation graph)\n",
    "output_tensors = model(inputs = [input_ids, token_type_ids, input_mask])\n",
    "\n",
    "#This will trigger model compilation, i.e., convert Rust computation graph to a unified high-level IR and lower it to TOSA IR\n",
    "model.compile(optimizer={\"type\":\"sgd\", \"lr\":\"0.01\", \"momentum\":\"0\", \"nesterov\":\"False\", \"weight_decay\":\"0\"},\n",
    "                    loss='sparse_categorical_crossentropy', metrics=['accuracy', 'sparse_categorical_crossentropy'])\n",
    "\n",
    "# modelir = model.dump_ir()\n",
    "\n",
    "\n",
    "print(\"Compiling TOSA model...\")\n",
    "tosa_ir= model.dump_tosa_ir()\n",
    "t1_stop = time.perf_counter()\n",
    "\n",
    "print(len(tosa_ir))\n",
    "\n",
    "\n",
    "print(\"Compiling Binary...\")\n",
    "\n",
    "if GPU:\n",
    "    binary = ireec.compile_str(tosa_ir,\n",
    "                    target_backends=[\"cuda\"], \n",
    "                    input_type=ireec.InputType.TOSA)\n",
    "    module = runtime.load_vm_flatbuffer(binary, driver=\"cuda\")\n",
    "else:\n",
    "    binary = ireec.compile_str(tosa_ir,\n",
    "                    target_backends=[\"llvm-cpu\"], \n",
    "                    input_type=ireec.InputType.TOSA)\n",
    "    module = runtime.load_vm_flatbuffer(binary,backend=\"llvm-cpu\") \n",
    "\n",
    "t2_stop = time.perf_counter()\n",
    "\n",
    "print(\"Bert****Ufront->TOSA Time: {:.3f}s, TOSA->Binary Time: {:.3f}s, Total Time: {:.3f}s\".format(t1_stop - t1_start, t2_stop - t1_stop, t2_stop - t1_start)) # print performance indicator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56d4c9e8-06da-4898-9177-95caadbe8299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.63 ms ± 36.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%timeit -n 100 module.forward(input_ids, token_type_ids, input_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3875b6-0d01-45b3-aa48-598b4c5c46e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "833f6a6a-2ec9-4dc8-a255-a54a5ead316b",
   "metadata": {},
   "source": [
    "# Compile & Run TF/Keras BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150bcb90-2223-48d9-af6c-9e6555cc0b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install bert-for-tf2 (need to fix its issue (InputSpec) under TF 2.6+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ad63ba2-0492-46d4-881d-d3d305540268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-19 18:01:45.466756: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/root/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2023-10-19 18:01:46.222370: W external/org_tensorflow/tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.1/lib64\n",
      "2023-10-19 18:01:46.241722: W external/org_tensorflow/tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.1/lib64\n",
      "2023-10-19 18:01:46.243395: W external/org_tensorflow/tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.1/lib64\n",
      "Could not search for non-variable resources. Concrete function internal representation may have changed.\n",
      "2023-10-19 18:01:50.686016: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2023-10-19 18:01:50.686227: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2023-10-19 18:01:57.552338: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2023-10-19 18:01:57.552554: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling TOSA model...\n",
      "777888366\n",
      "Compiling Binary...\n",
      "Bert****Ufront->TOSA Time: 28.472s, TOSA->Binary Time: 4.853s, Total Time: 33.325s\n"
     ]
    }
   ],
   "source": [
    "from bert import BertModelLayer\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from ufront.keras.model import UFrontKeras\n",
    "import iree.compiler as ireec\n",
    "from iree import runtime\n",
    "import time\n",
    "GPU = True\n",
    "\n",
    "l_bert = BertModelLayer(**BertModelLayer.Params(\n",
    "  vocab_size               = 16000,        # embedding params\n",
    "  use_token_type           = True,\n",
    "  use_position_embeddings  = True,\n",
    "  token_type_vocab_size    = 16000,\n",
    "\n",
    "  num_layers               = 12,           # transformer encoder params\n",
    "  hidden_size              = 768,\n",
    "  hidden_dropout           = 0.1,\n",
    "  intermediate_size        = 4*768,\n",
    "  intermediate_activation  = \"gelu\",\n",
    "\n",
    "  adapter_size             = None,         # see arXiv:1902.00751 (adapter-BERT)\n",
    "\n",
    "  shared_layer             = False,        # True for ALBERT (arXiv:1909.11942)\n",
    "  embedding_size           = None,         # None for BERT, wordpiece embedding size for ALBERT\n",
    "  num_heads = 12,\n",
    "  # name                     = \"bert\"        # any other Keras layer params\n",
    "))\n",
    "\n",
    "input_ids = np.array([[31, 51, 99], [15, 5, 0]], dtype='int32')\n",
    "input_mask = np.array([[1, 1, 1], [1, 1, 0]], dtype='int32')\n",
    "token_type_ids = np.array([[0, 0, 1], [0, 1, 0]], dtype='int32')\n",
    "\n",
    "max_seq_len = 3\n",
    "l_input_ids      = keras.layers.Input(shape=(max_seq_len,), dtype='int32')\n",
    "l_token_type_ids = keras.layers.Input(shape=(max_seq_len,), dtype='int32')\n",
    "\n",
    "output = l_bert([l_input_ids, l_token_type_ids])          # [batch_size, max_seq_len, hidden_size]\n",
    "net = keras.Model(inputs=[l_input_ids, l_token_type_ids], outputs=output)\n",
    "\n",
    "t1_start = time.perf_counter()\n",
    "#build UFront model\n",
    "model = UFrontKeras(net, inputs = [input_ids, token_type_ids], batch_size = 1, transformer=True, pass_weights=True)\n",
    "\n",
    "\n",
    "model.compile(optimizer={\"type\":\"sgd\", \"lr\":\"0.01\", \"momentum\":\"0\", \"nesterov\":\"False\", \"weight_decay\":\"0\"},\n",
    "                        loss='sparse_categorical_crossentropy', metrics=['accuracy', 'sparse_categorical_crossentropy'])\n",
    "\n",
    "# modelir = model.dump_ir()\n",
    "\n",
    "# print(modelir)\n",
    "\n",
    "print(\"Compiling TOSA model...\")\n",
    "tosa_ir= model.dump_tosa_ir()\n",
    "t1_stop = time.perf_counter()\n",
    "\n",
    "print(len(tosa_ir))\n",
    "\n",
    "print(\"Compiling Binary...\")\n",
    "\n",
    "if GPU:\n",
    "    binary = ireec.compile_str(tosa_ir,\n",
    "                    target_backends=[\"cuda\"], \n",
    "                    input_type=ireec.InputType.TOSA)\n",
    "    module = runtime.load_vm_flatbuffer(binary, driver=\"cuda\")\n",
    "else:\n",
    "    binary = ireec.compile_str(tosa_ir,\n",
    "                    target_backends=[\"llvm-cpu\"], \n",
    "                    input_type=ireec.InputType.TOSA)\n",
    "    module = runtime.load_vm_flatbuffer(binary,backend=\"llvm-cpu\") \n",
    "\n",
    "t2_stop = time.perf_counter()\n",
    "\n",
    "print(\"Bert****Ufront->TOSA Time: {:.3f}s, TOSA->Binary Time: {:.3f}s, Total Time: {:.3f}s\".format(t1_stop - t1_start, t2_stop - t1_stop, t2_stop - t1_start)) # print performance indicator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f2ad848-5d8b-4724-b81c-e30b026b45a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.51 ms ± 26.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 100 module.forward(input_ids, token_type_ids)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
