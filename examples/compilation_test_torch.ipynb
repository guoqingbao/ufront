{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5864c833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://github.com/iree-org/iree/releases/tag/candidate-20230512.517\n",
      "Collecting iree-compiler==20230524.529\n",
      "  Downloading iree_compiler-20230524.529-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (577 bytes)\n",
      "Collecting iree-runtime==20230524.529\n",
      "  Downloading iree_runtime-20230524.529-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: numpy in /root/anaconda3/envs/triton/lib/python3.10/site-packages (from iree-compiler==20230524.529) (1.26.2)\n",
      "Collecting PyYAML (from iree-compiler==20230524.529)\n",
      "  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Downloading iree_compiler-20230524.529-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (55.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 MB\u001b[0m \u001b[31m827.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading iree_runtime-20230524.529-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m838.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.5/705.5 kB\u001b[0m \u001b[31m860.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyYAML, iree-runtime, iree-compiler\n",
      "Successfully installed PyYAML-6.0.1 iree-compiler-20230524.529 iree-runtime-20230524.529\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install iree-compiler==20230524.529 iree-runtime==20230524.529 -f https://github.com/iree-org/iree/releases/tag/candidate-20230512.517"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b94a5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/llvm/torch-mlir/releases/tag/snapshot-20230525.849 download and install torch-mlir\n",
    "\n",
    "# !pip install torch-mlir==20230525.849 -f https://github.com/llvm/torch-mlir/releases/download/snapshot-20230525.849/torch_mlir-20230525.849-cp310-cp310-linux_x86_64.whl --no-dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bd1686",
   "metadata": {},
   "source": [
    "# Pytorch Model (UFront)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f876afe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/triton/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libc10_cuda.so: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some of the onnx models requires onnxsim library, please install onnxsim before usage!\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import time\n",
    "import torch\n",
    "from torchvision.models import resnet18, resnet50, squeezenet1_1, regnet_x_32gf, maxvit_t, shufflenet_v2_x1_5, inception_v3, mobilenet_v3_small, efficientnet_v2_s, densenet121, convnext_small\n",
    "import torchvision.models as models\n",
    "from ufront.pytorch.model import UFrontTorch\n",
    "import argparse\n",
    "import ctypes\n",
    "from iree.compiler import tools\n",
    "from iree import runtime\n",
    "import iree.runtime as ireert\n",
    "import iree.compiler as ireec\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "import torch\n",
    "import iree.runtime as ireert\n",
    "import iree.compiler as ireec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67e7ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchvision==0.16.0 --no-dependencies\n",
    "# !pip install torch==2.1.0 --no-dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "897848dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /root/ufront-0.1.1-cp310-cp310-manylinux_2_28_x86_64.whl\n",
      "Requirement already satisfied: onnx in /root/anaconda3/envs/triton/lib/python3.10/site-packages (from ufront==0.1.1) (1.16.0)\n",
      "Requirement already satisfied: tf2onnx in /root/anaconda3/envs/triton/lib/python3.10/site-packages (from ufront==0.1.1) (1.16.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /root/anaconda3/envs/triton/lib/python3.10/site-packages (from onnx->ufront==0.1.1) (1.26.2)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /root/anaconda3/envs/triton/lib/python3.10/site-packages (from onnx->ufront==0.1.1) (3.20.3)\n",
      "Requirement already satisfied: requests in /root/anaconda3/envs/triton/lib/python3.10/site-packages (from tf2onnx->ufront==0.1.1) (2.31.0)\n",
      "Requirement already satisfied: six in /root/anaconda3/envs/triton/lib/python3.10/site-packages (from tf2onnx->ufront==0.1.1) (1.16.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /root/anaconda3/envs/triton/lib/python3.10/site-packages (from tf2onnx->ufront==0.1.1) (24.3.25)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/anaconda3/envs/triton/lib/python3.10/site-packages (from requests->tf2onnx->ufront==0.1.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/anaconda3/envs/triton/lib/python3.10/site-packages (from requests->tf2onnx->ufront==0.1.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/anaconda3/envs/triton/lib/python3.10/site-packages (from requests->tf2onnx->ufront==0.1.1) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/anaconda3/envs/triton/lib/python3.10/site-packages (from requests->tf2onnx->ufront==0.1.1) (2024.2.2)\n",
      "Installing collected packages: ufront\n",
      "Successfully installed ufront-0.1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install /root/ufront-0.1.1-cp310-cp310-manylinux_2_28_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ddbd21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV3****Ufront->TOSA Time: 0.240s, TOSA->Binary Time: 2.635s, Total Time: 2.875s\n",
      "MobileNetV3 - 1.350 ± 0.000 ms\n",
      "ShuffleNetV2****Ufront->TOSA Time: 0.345s, TOSA->Binary Time: 1.923s, Total Time: 2.268s\n",
      "ShuffleNetV2 - 2.420 ± 0.000 ms\n",
      "ResNet18****Ufront->TOSA Time: 0.362s, TOSA->Binary Time: 1.696s, Total Time: 2.059s\n",
      "ResNet18 - 2.891 ± 0.008 ms\n",
      "ResNet50****Ufront->TOSA Time: 0.777s, TOSA->Binary Time: 3.141s, Total Time: 3.918s\n",
      "ResNet50 - 6.039 ± 0.028 ms\n",
      "SqueezeNet****Ufront->TOSA Time: 0.064s, TOSA->Binary Time: 1.300s, Total Time: 1.364s\n",
      "SqueezeNet - 1.108 ± 0.004 ms\n",
      "DenseNet121****Ufront->TOSA Time: 1.203s, TOSA->Binary Time: 5.280s, Total Time: 6.483s\n",
      "DenseNet121 - 7.640 ± 0.004 ms\n",
      "InceptionV3****Ufront->TOSA Time: 0.957s, TOSA->Binary Time: 4.099s, Total Time: 5.056s\n",
      "InceptionV3 - 12.080 ± 0.040 ms\n",
      "ViT_B16****Ufront->TOSA Time: 2.399s, TOSA->Binary Time: 4.911s, Total Time: 7.311s\n",
      "ViT_B16 - 29.400 ± 0.089 ms\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "import numpy as np\n",
    "from iree.runtime.benchmark import benchmark_module\n",
    "\n",
    "input_sample = np.random.uniform(low=0.0, high=1.0, size=(batch_size, 3, 224, 224)).astype(np.float32)\n",
    "input = torch.Tensor(input_sample)\n",
    "\n",
    "model_list = {\"MobileNetV3\":mobilenet_v3_small(pretrained=False), \"ShuffleNetV2\":shufflenet_v2_x1_5(pretrained=False),\n",
    "            \"ResNet18\":resnet18(pretrained=False), \"ResNet50\":resnet50(pretrained=False), \"SqueezeNet\":squeezenet1_1(pretrained=False),\n",
    "            \"DenseNet121\":densenet121(pretrained=False), \"InceptionV3\":inception_v3(pretrained=False), \"ViT_B16\":models.vision_transformer.vit_b_16(weights=False, dropout=0.1)}\n",
    "\n",
    "for modelname, net in model_list.items():\n",
    "    net.train(False) \n",
    "\n",
    "    t1_start = time.perf_counter()\n",
    "    model = UFrontTorch(net, batch_size=batch_size, pass_weights=True) # convert torch model to ufront model\n",
    "    #This will trigger Rust frontend for actual model conversion and graph building\n",
    "    #operators can also be managed by python side (each operator here corresponding to an operator in the Rust computation graph)\n",
    "    output_tensors = model(inputs = [input])\n",
    "\n",
    "    #This will trigger model compilation, i.e., convert Rust computation graph to a unified high-level IR and lower it to TOSA IR\n",
    "    model.compile(optimizer={\"type\":\"sgd\", \"lr\":\"0.01\", \"momentum\":\"0\", \"nesterov\":\"False\", \"weight_decay\":\"0\"},\n",
    "                        loss='sparse_categorical_crossentropy', metrics=['accuracy', 'sparse_categorical_crossentropy'])\n",
    "    tosa_ir= model.dump_tosa_ir()\n",
    "\n",
    "    t1_stop = time.perf_counter()\n",
    "\n",
    "    binary = ireec.compile_str(tosa_ir,\n",
    "                    target_backends=[\"cuda\"], \n",
    "                    input_type=ireec.InputType.TOSA)\n",
    "    t2_stop = time.perf_counter()\n",
    "\n",
    "    print(modelname + \"****Ufront->TOSA Time: {:.3f}s, TOSA->Binary Time: {:.3f}s, Total Time: {:.3f}s\".format(t1_stop - t1_start, t2_stop - t1_stop, t2_stop - t1_start)) # print performance indicator\n",
    "    module = runtime.load_vm_flatbuffer(binary, driver=\"cuda\")\n",
    "    tms = []\n",
    "    for i in range(10):\n",
    "        ret = benchmark_module(module.vm_module, entry_functiong=\"forward\", inputs=[\"1x3x224x224xf32=1\"], device=\"cuda\")\n",
    "        tm = ret[0].time\n",
    "        tms.append(float(tm[0:-3]))\n",
    "    print(\"{} - {:.3f} ± {:.3f} ms\".format(modelname, np.mean(tms), np.std(tms)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b96c9eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6f07091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "327f24a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling TOSA model...\n",
      "Compiling Binary...\n",
      "Bert****Ufront->TOSA Time: 2.848s, TOSA->Binary Time: 4.363s, Total Time: 7.212s\n",
      "3.4 ms ± 20.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "from ufront.pytorch.model import UFrontTorch \n",
    "import iree.compiler as ireec\n",
    "from iree import runtime\n",
    "from torch_bert import BertModel, BertConfig\n",
    "import torch\n",
    "import time\n",
    "input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n",
    "input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n",
    "token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])\n",
    "\n",
    "config = BertConfig(vocab_size_or_config_json_file=16000, hidden_size=768,\n",
    "    num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n",
    "\n",
    "net = BertModel(config=config)\n",
    "net.eval()\n",
    "\n",
    "t1_start = time.perf_counter()\n",
    "model = UFrontTorch(net, batch_size=1, pass_weights=True) # convert torch model to ufront model\n",
    "#This will trigger Rust frontend for actual model conversion and graph building\n",
    "#operators can also be managed by python side (each operator here corresponding to an operator in the Rust computation graph)\n",
    "output_tensors = model(inputs = [input_ids, token_type_ids, input_mask])\n",
    "\n",
    "#This will trigger model compilation, i.e., convert Rust computation graph to a unified high-level IR and lower it to TOSA IR\n",
    "model.compile(optimizer={\"type\":\"sgd\", \"lr\":\"0.01\", \"momentum\":\"0\", \"nesterov\":\"False\", \"weight_decay\":\"0\"},\n",
    "                    loss='sparse_categorical_crossentropy', metrics=['accuracy', 'sparse_categorical_crossentropy'])\n",
    "\n",
    "print(\"Compiling TOSA model...\")\n",
    "tosa_ir= model.dump_tosa_ir()\n",
    "t1_stop = time.perf_counter()\n",
    "print(\"Compiling Binary...\")\n",
    "binary = ireec.compile_str(tosa_ir,\n",
    "                target_backends=[\"cuda\"], \n",
    "                input_type=ireec.InputType.TOSA)\n",
    "t2_stop = time.perf_counter()\n",
    "print(\"Bert****Ufront->TOSA Time: {:.3f}s, TOSA->Binary Time: {:.3f}s, Total Time: {:.3f}s\".format(t1_stop - t1_start, t2_stop - t1_stop, t2_stop - t1_start)) # print performance indicator\n",
    "module = runtime.load_vm_flatbuffer(binary, driver=\"cuda\")\n",
    "\n",
    "%timeit -n 100 module.forward(input_ids, token_type_ids, input_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ac8f274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iree-compiler            20230524.529\n",
      "iree-runtime             20230524.529\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep iree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bdd99ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch                    2.1.0.dev20230522+cpu\n",
      "torch-mlir               20230523.847\n",
      "torchvision              0.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a10c935",
   "metadata": {},
   "source": [
    "## Pytorch Model (Torch-MLIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42fb8162-39d8-4167-9ffd-11b25bdcc161",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/triton/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libc10_cuda.so: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import io\n",
    "import numpy as np\n",
    "import time\n",
    "import torch_mlir\n",
    "from torchvision.models import resnet18, resnet50, squeezenet1_1, regnet_x_32gf, maxvit_t, shufflenet_v2_x1_5, inception_v3, mobilenet_v3_small, efficientnet_v2_s, densenet121, convnext_small\n",
    "import torchvision.models as models\n",
    "from iree import runtime\n",
    "from typing import Optional\n",
    "from torch.utils._pytree import tree_map\n",
    "import iree.runtime as ireert\n",
    "import iree.compiler as ireec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc40ecf0-0f53-465b-9911-5c54c15b9b7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IREEInvoker:\n",
    "    \"\"\"A wrapper around an IREE module that provides a Pythonic interface.\n",
    "    \n",
    "    Specifically, this adapts `module.forward(...)` and similar calls into\n",
    "    lower-level calls into the functions in the IREE module, and also converts\n",
    "    between the IREE and Torch types.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, iree_module):\n",
    "        self._iree_module = iree_module\n",
    "        self.device = iree_module._context.config.device\n",
    "\n",
    "    def __getattr__(self, function_name: str):\n",
    "        def invoke(*args):\n",
    "            def wrap(x):\n",
    "                if isinstance(x, torch.Tensor):\n",
    "                    return ireert.asdevicearray(self.device, x)\n",
    "                return x\n",
    "            def unwrap(x):\n",
    "                if isinstance(x, ireert.DeviceArray):\n",
    "                    return torch.from_numpy(np.asarray(x).copy())\n",
    "                return x\n",
    "            iree_args = tree_map(wrap, args)\n",
    "            result = self._iree_module[function_name](*iree_args)\n",
    "            return tree_map(unwrap, result)\n",
    "        return invoke\n",
    "    \n",
    "def _map_target_backend_to_driver(target_backend):\n",
    "    if target_backend == \"cuda\":\n",
    "        return \"cuda\"\n",
    "    if target_backend == \"vulkan\":\n",
    "        return \"vulkan\"\n",
    "    if target_backend in (\"llvm-cpu\", \"vmvx\"):\n",
    "        return \"local-sync\"\n",
    "    raise ValueError(f\"Unknown target backend: {target_backend}\")\n",
    "\n",
    "def load_vmfb(flatbuffer, backend=\"llvm-cpu\"):\n",
    "    \"\"\"Load an IREE Flatbuffer into an in-process runtime wrapper.\n",
    "    The wrapper accepts and returns `torch.Tensor` types.\n",
    "    \"\"\"\n",
    "    config = ireert.Config(driver_name=_map_target_backend_to_driver(backend))\n",
    "    ctx = ireert.SystemContext(config=config)\n",
    "    vm_module = ireert.VmModule.from_flatbuffer(ctx.instance, flatbuffer)\n",
    "    ctx.add_vm_module(vm_module)\n",
    "    return IREEInvoker(ctx.modules.module)\n",
    "\n",
    "def compile_to_vmfb(mlir_module, target_backend=\"llvm-cpu\", \n",
    "                    cuda_llvm_target_arch: Optional[str] = None):\n",
    "    \"\"\"Compile an MLIR module to an IREE Flatbuffer.\n",
    "    The module is expected to be in the format produced by `torch_mlir.compile`\n",
    "    with `OutputType.LINALG_ON_TENSORS`.\n",
    "    TODO: Expose more compiler options.\n",
    "    \"\"\"\n",
    "    extra_args = []\n",
    "    if cuda_llvm_target_arch is not None:\n",
    "        arch_flag = f\"--iree-hal-cuda-llvm-target-arch={cuda_llvm_target_arch}\"\n",
    "        extra_args.append(arch_flag)\n",
    "    bytecode_stream = io.BytesIO()\n",
    "    mlir_module.operation.write_bytecode(bytecode_stream)\n",
    "    bytecode = bytecode_stream.getvalue()\n",
    "    \n",
    "    return ireec.compile_str(bytecode,\n",
    "                             target_backends=[target_backend],\n",
    "                             input_type=ireec.InputType.TM_TENSOR,\n",
    "                             extra_args=extra_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b4c0c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**********Processing model MobileNetV3\n",
      "MobileNetV3****Compilation Time: 3.508s\n",
      "Calculating forward latency:\n",
      "  MobileNetV3 - 1.628 ± 0.004 ms\n",
      "\n",
      "**********Processing model ShuffleNetV2\n",
      "Lowering TorchScript IR -> Torch Backend IR failed with the following diagnostics:\n",
      "\n",
      "\n",
      "python exceptio\n",
      "\n",
      "**********Processing model ResNet18\n",
      "ResNet18****Compilation Time: 1.651s\n",
      "Calculating forward latency:\n",
      "  ResNet18 - 6.510 ± 0.021 ms\n",
      "\n",
      "**********Processing model ResNet50\n",
      "ResNet50****Compilation Time: 3.494s\n",
      "Calculating forward latency:\n",
      "  ResNet50 - 15.080 ± 0.040 ms\n",
      "\n",
      "**********Processing model SqueezeNet\n",
      "SqueezeNet****Compilation Time: 1.657s\n",
      "Calculating forward latency:\n",
      "  SqueezeNet - 1.650 ± 0.000 ms\n",
      "\n",
      "**********Processing model DenseNet121\n",
      "Lowering Torch Backend IR -> Linalg-on-Tensors Backend IR failed with the following diagnostics:\n",
      "\n",
      "\n",
      "p\n",
      "\n",
      "**********Processing model InceptionV3\n",
      "Lowering TorchScript IR -> Torch Backend IR failed with the following diagnostics:\n",
      "\n",
      "\n",
      "python exceptio\n",
      "\n",
      "**********Processing model ViT_B16\n",
      "Lowering TorchScript IR -> Torch Backend IR failed with the following diagnostics:\n",
      "\n",
      "\n",
      "python exceptio\n"
     ]
    }
   ],
   "source": [
    "from iree.runtime.benchmark import benchmark_module\n",
    "input_sample = np.random.uniform(low=0.0, high=1.0, size=(batch_size, 3, 224, 224)).astype(np.float32)\n",
    "input = torch.Tensor(input_sample)\n",
    "model_list = {\"MobileNetV3\":mobilenet_v3_small(pretrained=False), \"ShuffleNetV2\":shufflenet_v2_x1_5(pretrained=False),\n",
    "            \"ResNet18\":resnet18(pretrained=False), \"ResNet50\":resnet50(pretrained=False), \"SqueezeNet\":squeezenet1_1(pretrained=False),\n",
    "            \"DenseNet121\":densenet121(pretrained=False), \"InceptionV3\":inception_v3(pretrained=False), \"ViT_B16\":models.vision_transformer.vit_b_16(weights=False)}\n",
    "\n",
    "for modelname, model in model_list.items():\n",
    "    print(\"\\r\\n**********Processing model \" + modelname)\n",
    "    try: \n",
    "        model.train(mode=False)\n",
    "        t1_start = time.perf_counter()\n",
    "        \n",
    "        ts_graph = torch.jit.script(model)\n",
    "        module_ir = torch_mlir.compile(ts_graph, input,\n",
    "                                            output_type=torch_mlir.OutputType.LINALG_ON_TENSORS)\n",
    "\n",
    "        binary = compile_to_vmfb(module_ir, target_backend=\"cuda\")\n",
    "\n",
    "        t2_stop = time.perf_counter()\n",
    "        module = runtime.load_vm_flatbuffer(binary, driver=\"cuda\")\n",
    "\n",
    "        print(modelname + \"****Compilation Time: {:.3f}s\".format(t2_stop - t1_start)) # print performance indicator\n",
    "\n",
    "        print(\"Calculating forward latency:\\n  \", end=\"\")\n",
    "        tms = []\n",
    "        for i in range(10):\n",
    "            ret = benchmark_module(module.vm_module, entry_functiong=\"forward\", inputs=[\"1x3x224x224xf32=1\"], device=\"cuda\")\n",
    "            tm = ret[0].time\n",
    "            tms.append(float(tm[0:-3]))\n",
    "        print(\"{} - {:.3f} ± {:.3f} ms\".format(modelname, np.mean(tms), np.std(tms)))\n",
    "    except Exception as e:\n",
    "        print(str(e)[:100]) #only print error head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179f4463",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
