{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0dbada4-d43b-4bd7-a08c-e1c6e1a4929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from iree import runtime\n",
    "from iree.compiler.transforms import ireec\n",
    "# The compiler re-exports API access to a number of dialects. If one of these\n",
    "# fails to import, it indicates a build issue.\n",
    "import numpy as np\n",
    "from iree.compiler import tools\n",
    "from iree.runtime.benchmark import benchmark_module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0669c8-dfdc-4c32-8f92-22f79711e87a",
   "metadata": {},
   "source": [
    "# Performance of IREE (Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fbe0342-6cf1-4fcc-b18e-f6e34647063e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnski96_3.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnski96_3.sm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model MobileNetV3 - Total Time: 22.685s\n",
      "Performing benchmark...\n",
      "Calculating forward latency:\n",
      "  77.8 ms ± 299 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpeopriwdk.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpeopriwdk.sm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model ResNet50 - Total Time: 18.991s\n",
      "Performing benchmark...\n",
      "Calculating forward latency:\n",
      "  204 ms ± 305 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp2i93g1jp.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp2i93g1jp.sm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model SqueezeNet - Total Time: 6.337s\n",
      "Performing benchmark...\n",
      "Calculating forward latency:\n",
      "  82.1 ms ± 466 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpt9b_fdzd.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpt9b_fdzd.sm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model ShuffleNet - Total Time: 17.519s\n",
      "Performing benchmark...\n",
      "Calculating forward latency:\n",
      "  83.5 ms ± 336 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp9lb0taga.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp9lb0taga.sm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model Inception3 - Total Time: 30.343s\n",
      "Performing benchmark...\n",
      "Calculating forward latency:\n",
      "  166 ms ± 798 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpu0959bvn.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpu0959bvn.sm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model DenseNet - Total Time: 44.449s\n",
      "Performing benchmark...\n",
      "Calculating forward latency:\n",
      "  178 ms ± 836 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpkzhyg36a.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpkzhyg36a.sm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model Vit - Total Time: 25.910s\n",
      "Performing benchmark...\n",
      "Calculating forward latency:\n",
      "  728 ms ± 1.55 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend\n",
    "from iree.tf.support import module_utils\n",
    "from vit_keras import vit\n",
    "from keras_def import SequentialCNN, ConcatenatedCNN, NestedCNN, ShuffleNet, SqueezeNet_11, ResNet18\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50, ResNet50V2, MobileNetV3Small, DenseNet121, InceptionV3, VGG16\n",
    "channels_first = False\n",
    "\n",
    "model_list = {\"MobileNetV3\":MobileNetV3Small, \"ResNet50\":ResNet50, \"SqueezeNet\":SqueezeNet_11, \"ShuffleNet\":ShuffleNet,\n",
    "              \"Inception3\":InceptionV3, \"DenseNet\":DenseNet121, \n",
    "             \"Vit\":vit.vit_b16}\n",
    "# model_list = {\"ResNet18\":ResNet18}\n",
    "\n",
    "INPUT_SHAPE = [1, 3, 224, 224] if channels_first else [1, 224, 224, 3]\n",
    "backend.set_image_data_format('channels_first' if channels_first else 'channels_last')\n",
    "x_train = np.random.uniform(low=0.0, high=1.0, size=(1, 3, 224, 224) if channels_first else (1, 224, 224, 3)).astype(np.float32)\n",
    "\n",
    "for modelname, Model in model_list.items():\n",
    "    \n",
    "    if modelname == \"Vit\":\n",
    "        model = Model(image_size=224, activation='relu', pretrained=False, include_top=True, pretrained_top=False, channel_first=channels_first)\n",
    "    elif modelname == \"SqueezeNet\":\n",
    "        model = Model(input_shape=tuple(INPUT_SHAPE[1:]), nb_classes=1000, channel_first=channels_first)\n",
    "    elif modelname == \"ShuffleNet\":\n",
    "        model = Model(include_top=True, input_shape=tuple(INPUT_SHAPE[1:]))\n",
    "    elif modelname == \"ResNet18\":\n",
    "        model = Model(classes=1000, input_shape=tuple(INPUT_SHAPE[1:]))\n",
    "    else:\n",
    "        model = Model(weights=None, include_top=True, input_shape=tuple(INPUT_SHAPE[1:]))\n",
    "        \n",
    "    t1_start = time.perf_counter()\n",
    "    # Wrap the model in a tf.Module to compile it with IREE.\n",
    "    class Module(tf.Module):\n",
    "      def __init__(self):\n",
    "        super(Module, self).__init__()\n",
    "        self.m = model\n",
    "        self.m.predict = lambda x: self.m.call(x, training=False)\n",
    "        self.predict = tf.function(\n",
    "            input_signature=[tf.TensorSpec(INPUT_SHAPE, tf.float32)])(model.predict)\n",
    "    \n",
    "    backend_choice = \"iree_llvmcpu (CPU)\" #@param [ \"iree_vmvx (CPU)\", \"iree_llvmcpu (CPU)\", \"iree_vulkan (GPU/SwiftShader)\" ]\n",
    "    backend_choice = backend_choice.split(\" \")[0]\n",
    "    backend = module_utils.BackendInfo(backend_choice)\n",
    "    compiled_model = backend.compile_from_class(Module, [\"predict\"])\n",
    "    t1_stop = time.perf_counter()\n",
    "    print(\"**** Model {} - Total Time: {:.3f}s\".format(modelname, t1_stop - t1_start)) # print performance indicator\n",
    "\n",
    "    print(\"Performing benchmark...\")\n",
    "    print(\"Calculating forward latency:\\n  \", end=\"\")\n",
    "    %timeit -n 100 compiled_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d62ff44-b8ba-4237-a550-ae721efe2101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44398303-bf91-4d6d-8e95-2071845f0509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0xzo9men.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0xzo9men.sm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model Bert - Total Time: 23.804s\n",
      "Performing benchmark...\n",
      "Calculating forward latency:\n",
      "  68.3 ms ± 219 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "from bert import BertModelLayer\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from ufront.keras.model import UFrontKeras\n",
    "import iree.compiler as ireec\n",
    "from iree import runtime\n",
    "import time\n",
    "from tensorflow.keras import backend\n",
    "from iree.tf.support import module_utils\n",
    "import iree\n",
    "GPU = False\n",
    "\n",
    "l_bert = BertModelLayer(**BertModelLayer.Params(\n",
    "  vocab_size               = 16000,        # embedding params\n",
    "  use_token_type           = True,\n",
    "  use_position_embeddings  = True,\n",
    "  token_type_vocab_size    = 16000,\n",
    "\n",
    "  num_layers               = 12,           # transformer encoder params\n",
    "  hidden_size              = 768,\n",
    "  hidden_dropout           = 0.1,\n",
    "  intermediate_size        = 4*768,\n",
    "  intermediate_activation  = \"gelu\",\n",
    "\n",
    "  adapter_size             = None,         # see arXiv:1902.00751 (adapter-BERT)\n",
    "\n",
    "  shared_layer             = False,        # True for ALBERT (arXiv:1909.11942)\n",
    "  embedding_size           = None,         # None for BERT, wordpiece embedding size for ALBERT\n",
    "  num_heads = 12,\n",
    "  # name                     = \"bert\"        # any other Keras layer params\n",
    "))\n",
    "\n",
    "input_ids = np.array([[31, 51, 99], [15, 5, 0]], dtype='int32')\n",
    "input_mask = np.array([[1, 1, 1], [1, 1, 0]], dtype='int32')\n",
    "token_type_ids = np.array([[0, 0, 1], [0, 1, 0]], dtype='int32')\n",
    "\n",
    "INPUT_SHAPE = [2, 3]\n",
    "max_seq_len = 3\n",
    "l_input_ids      = keras.layers.Input(shape=(max_seq_len,), dtype='int32')\n",
    "l_token_type_ids = keras.layers.Input(shape=(max_seq_len,), dtype='int32')\n",
    "\n",
    "output = l_bert([l_input_ids, l_token_type_ids])          # [batch_size, max_seq_len, hidden_size]\n",
    "model = keras.Model(inputs=[l_input_ids, l_token_type_ids], outputs=output)\n",
    "\n",
    "t1_start = time.perf_counter()\n",
    "\n",
    "\n",
    "modelname = \"Bert\"\n",
    "BATCH_SIZE = INPUT_SHAPE[0]\n",
    "SEQUENCE_LENGTH = INPUT_SHAPE[1]\n",
    "bert_input = [tf.TensorSpec(shape=[BATCH_SIZE,SEQUENCE_LENGTH],dtype=tf.int32),\n",
    "            tf.TensorSpec(shape=[BATCH_SIZE,SEQUENCE_LENGTH], dtype=tf.int32)]\n",
    "class BertModule(tf.Module):\n",
    "    def __init__(self):\n",
    "        super(BertModule, self).__init__()\n",
    "        dict_outputs = False\n",
    "        self.m = model\n",
    "        self.m.predict = lambda x: self.m.call(x, training=False)\n",
    "        \n",
    "    @tf.function(input_signature=bert_input)\n",
    "    def predict(self,input_word_ids, segment_ids):\n",
    "        inputs = [input_word_ids, segment_ids]\n",
    "        return self.m.predict(inputs)\n",
    "if GPU:\n",
    "    binary = iree.compiler.tf.compile_module(\n",
    "            BertModule(),\n",
    "            target_backends=[\"cuda\"],\n",
    "            exported_names=[\"predict\"])\n",
    "    \n",
    "    t1_stop = time.perf_counter()\n",
    "    print(\"**** Model {} - Total Time: {:.3f}s\".format(modelname, t1_stop - t1_start)) # print performance indicator\n",
    "\n",
    "    \n",
    "    module = runtime.load_vm_flatbuffer(binary, driver=\"cuda\")\n",
    "    print(\"Calculating forward latency:\\n  \", end=\"\")\n",
    "    %timeit -n 100 module.predict(input_ids, token_type_ids)\n",
    "    # tms = []\n",
    "    # for i in range(10):\n",
    "    #     ret = benchmark_module(module.vm_module, entry_functiong=\"predict\", inputs=[\"1x3x224x224xf32=1\"], device=\"cuda\")\n",
    "    #     tm = ret[0].time\n",
    "    #     tms.append(float(tm[0:-3]))\n",
    "    # print(\"{} - {:.3f} ± {:.3f} ms\".format(modelname, np.mean(tms), np.std(tms)))\n",
    "else:\n",
    "    backend_choice = \"iree_llvmcpu (CPU)\" #@param [ \"iree_vmvx (CPU)\", \"iree_llvmcpu (CPU)\", \"iree_vulkan (GPU/SwiftShader)\" ]\n",
    "    backend_choice = backend_choice.split(\" \")[0]\n",
    "    backend = module_utils.BackendInfo(backend_choice)\n",
    "    compiled_model = backend.compile_from_class(BertModule, [\"predict\"])\n",
    "    t1_stop = time.perf_counter()\n",
    "    print(\"**** Model {} - Total Time: {:.3f}s\".format(modelname, t1_stop - t1_start)) # print performance indicator\n",
    "\n",
    "    print(\"Performing benchmark...\")\n",
    "    print(\"Calculating forward latency:\\n  \", end=\"\")\n",
    "    %timeit -n 100 compiled_model.predict(input_ids, token_type_ids)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "359d0365-5a77-4279-8d9e-7caaabd2cb26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IREE DeviceArray: shape=[2, 3, 768], dtype=<class 'numpy.float32'>>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.predict(input_ids, token_type_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e43299e-1c2f-4bc4-b3a5-1ff1fe7360ac",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f6ea541-fdee-4e47-8e55-daee2a1dc71f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp48pzv4te.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp48pzv4te.sm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model ResNet18 - Total Time: 8.131s\n",
      "Calculating forward latency:\n",
      "  4.2 ms ± 27.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "INFO:tensorflow:Assets written to: /tmp/tmprseqvwkc.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmprseqvwkc.sm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model MobileNetV3 - Total Time: 16.621s\n",
      "Calculating forward latency:\n",
      "  2.44 ms ± 46.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpwi5kmuir.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwi5kmuir.sm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model ResNet50 - Total Time: 17.069s\n",
      "Calculating forward latency:\n",
      "  7.17 ms ± 50.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpcs2s15al.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpcs2s15al.sm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model SqueezeNet - Total Time: 5.435s\n",
      "Calculating forward latency:\n",
      "  2.24 ms ± 38.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpcrchwiv4.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpcrchwiv4.sm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model ShuffleNet - Total Time: 15.593s\n",
      "Calculating forward latency:\n",
      "  3.37 ms ± 48 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpyqa34p21.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpyqa34p21.sm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model Inception3 - Total Time: 27.603s\n",
      "Calculating forward latency:\n",
      "  11.7 ms ± 58.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp5chpi6ja.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5chpi6ja.sm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model DenseNet - Total Time: 39.795s\n",
      "Calculating forward latency:\n",
      "  8.17 ms ± 120 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpvskkpbfl.sm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpvskkpbfl.sm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Model Vit - Total Time: 25.975s\n",
      "Calculating forward latency:\n",
      "  35.2 ms ± 119 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import iree\n",
    "import numpy as np\n",
    "from iree import runtime\n",
    "from tensorflow.keras import backend\n",
    "from iree.tf.support import module_utils\n",
    "from vit_keras import vit\n",
    "from keras_def import SequentialCNN, ConcatenatedCNN, NestedCNN, ShuffleNet, SqueezeNet_11, ResNet18\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50, ResNet50V2, MobileNetV3Small, DenseNet121, InceptionV3, VGG16\n",
    "channels_first = True\n",
    "GPU = True\n",
    "model_list = {\"ResNet18\":ResNet18, \"MobileNetV3\":MobileNetV3Small, \"ResNet50\":ResNet50, \"SqueezeNet\":SqueezeNet_11, \"ShuffleNet\":ShuffleNet,\n",
    "              \"Inception3\":InceptionV3, \"DenseNet\":DenseNet121, \n",
    "             \"Vit\":vit.vit_b16} \n",
    "input = np.random.uniform(low=0.0, high=1.0, size=(1, 3, 224, 224) if channels_first else (1, 224, 224, 3)).astype(np.float32)\n",
    "\n",
    "INPUT_SHAPE = [1, 3, 224, 224] if channels_first else [1, 224, 224, 3]\n",
    "backend.set_image_data_format('channels_first' if channels_first else 'channels_last')\n",
    "\n",
    "for modelname, Model in model_list.items():\n",
    "    \n",
    "    if modelname == \"Vit\":\n",
    "        model = Model(image_size=224, activation='relu', pretrained=False, include_top=True, pretrained_top=False, channel_first=channels_first)\n",
    "    elif modelname == \"SqueezeNet\":\n",
    "        model = Model(input_shape=tuple(INPUT_SHAPE[1:]), nb_classes=1000, channel_first=channels_first)\n",
    "    elif modelname == \"ShuffleNet\":\n",
    "        model = Model(include_top=True, input_shape=tuple(INPUT_SHAPE[1:]))\n",
    "    elif modelname == \"ResNet18\":\n",
    "        model = Model(classes=1000, input_shape=tuple(INPUT_SHAPE[1:]))\n",
    "    else:\n",
    "        model = Model(weights=None, include_top=True, input_shape=tuple(INPUT_SHAPE[1:]))\n",
    "        \n",
    "    t1_start = time.perf_counter()\n",
    "    # Wrap the model in a tf.Module to compile it with IREE.\n",
    "    class Module(tf.Module):\n",
    "      def __init__(self):\n",
    "        super(Module, self).__init__()\n",
    "        self.m = model\n",
    "        self.m.predict = lambda x: self.m.call(x, training=False)\n",
    "        self.predict = tf.function(\n",
    "            input_signature=[tf.TensorSpec(INPUT_SHAPE, tf.float32)])(model.predict)\n",
    "    \n",
    "    if GPU:\n",
    "        binary = iree.compiler.tf.compile_module(\n",
    "                Module(),\n",
    "                target_backends=[\"cuda\"],\n",
    "                exported_names=[\"predict\"])\n",
    "        compiled_model = runtime.load_vm_flatbuffer(binary, driver=\"cuda\")\n",
    "    else:\n",
    "        backend_choice = \"iree_llvmcpu (CPU)\" #@param [ \"iree_vmvx (CPU)\", \"iree_llvmcpu (CPU)\", \"iree_vulkan (GPU/SwiftShader)\" ]\n",
    "        backend_choice = backend_choice.split(\" \")[0]\n",
    "        backend = module_utils.BackendInfo(backend_choice)\n",
    "        compiled_model = backend.compile_from_class(Module, [\"predict\"])\n",
    "    t1_stop = time.perf_counter()\n",
    "    print(\"**** Model {} - Total Time: {:.3f}s\".format(modelname, t1_stop - t1_start)) # print performance indicator\n",
    "\n",
    "    print(\"Calculating forward latency:\\n  \", end=\"\")\n",
    "    # tms = []\n",
    "    # for i in range(10):\n",
    "    #     ret = benchmark_module(module.vm_module, entry_functiong=\"predict\", inputs=[\"1x3x224x224xf32=1\"], device=\"cuda\")\n",
    "    #     tm = ret[0].time\n",
    "    #     tms.append(float(tm[0:-3]))\n",
    "    # print(\"{} - {:.3f} ± {:.3f} ms\".format(modelname, np.mean(tms), np.std(tms)))\n",
    "    %timeit -n 100 compiled_model.predict(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46b6151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a952773c-fbcc-48e5-aa20-49180124fc92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5282355e-5db6-42a6-bd89-735d680a7711",
   "metadata": {},
   "source": [
    "# Performance of Ufront (Keras Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb2b7e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tf2onnx.tf_loader:Could not search for non-variable resources. Concrete function internal representation may have changed.\n",
      "2023-10-24 17:41:29.489666: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2023-10-24 17:41:29.489813: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2023-10-24 17:41:30.070867: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2023-10-24 17:41:30.071026: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling TOSA model...\n",
      "ResNet18****Ufront->TOSA Time: 2.586s, TOSA->Binary Time: 15.149s, Total Time: 17.734s\n",
      "3.65 ms ± 22.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tf2onnx.tf_loader:Could not search for non-variable resources. Concrete function internal representation may have changed.\n",
      "2023-10-24 17:41:50.552071: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2023-10-24 17:41:50.552224: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2023-10-24 17:41:51.058447: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2023-10-24 17:41:51.058586: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling TOSA model...\n",
      "MobileNetV3****Ufront->TOSA Time: 3.936s, TOSA->Binary Time: 7.248s, Total Time: 11.184s\n",
      "1.81 ms ± 25.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tf2onnx.tf_loader:Could not search for non-variable resources. Concrete function internal representation may have changed.\n",
      "2023-10-24 17:42:03.647954: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2023-10-24 17:42:03.648097: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2023-10-24 17:42:05.539141: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2023-10-24 17:42:05.539295: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling TOSA model...\n",
      "ResNet50****Ufront->TOSA Time: 6.498s, TOSA->Binary Time: 29.435s, Total Time: 35.933s\n",
      "6.81 ms ± 25.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tf2onnx.tf_loader:Could not search for non-variable resources. Concrete function internal representation may have changed.\n",
      "2023-10-24 17:42:44.260989: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2023-10-24 17:42:44.261126: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2023-10-24 17:42:44.421330: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2023-10-24 17:42:44.421466: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling TOSA model...\n",
      "SqueezeNet****Ufront->TOSA Time: 0.616s, TOSA->Binary Time: 3.592s, Total Time: 4.208s\n",
      "2.19 ms ± 39.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tf2onnx.tf_loader:Could not search for non-variable resources. Concrete function internal representation may have changed.\n",
      "2023-10-24 17:42:51.300706: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2023-10-24 17:42:51.300878: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2023-10-24 17:42:51.884569: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2023-10-24 17:42:51.884744: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling TOSA model...\n",
      "ShuffleNet****Ufront->TOSA Time: 2.824s, TOSA->Binary Time: 4.442s, Total Time: 7.265s\n",
      "2.84 ms ± 50.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tf2onnx.tf_loader:Could not search for non-variable resources. Concrete function internal representation may have changed.\n",
      "2023-10-24 17:43:01.656539: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2023-10-24 17:43:01.656715: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2023-10-24 17:43:02.940418: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2023-10-24 17:43:02.940584: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling TOSA model...\n",
      "Inception3****Ufront->TOSA Time: 6.673s, TOSA->Binary Time: 28.789s, Total Time: 35.462s\n",
      "10.8 ms ± 18.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tf2onnx.tf_loader:Could not search for non-variable resources. Concrete function internal representation may have changed.\n",
      "2023-10-24 17:43:46.701273: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2023-10-24 17:43:46.701442: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2023-10-24 17:43:48.062444: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2023-10-24 17:43:48.062608: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling TOSA model...\n",
      "DenseNet****Ufront->TOSA Time: 6.985s, TOSA->Binary Time: 16.366s, Total Time: 23.351s\n",
      "7.11 ms ± 44.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tf2onnx.tf_loader:Could not search for non-variable resources. Concrete function internal representation may have changed.\n",
      "2023-10-24 17:44:17.513027: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2023-10-24 17:44:17.513197: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2023-10-24 17:44:23.491630: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2023-10-24 17:44:23.491811: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling TOSA model...\n",
      "Vit****Ufront->TOSA Time: 24.979s, TOSA->Binary Time: 5.934s, Total Time: 30.913s\n",
      "30.1 ms ± 105 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import iree\n",
    "from iree import runtime\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend\n",
    "from iree.tf.support import module_utils\n",
    "from vit_keras import vit\n",
    "from keras_def import SequentialCNN, ConcatenatedCNN, NestedCNN, ShuffleNet, SqueezeNet_11, ResNet18\n",
    "from ufront.keras.model import UFrontKeras\n",
    "import iree.compiler as ireec\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50, ResNet50V2, MobileNetV3Small, DenseNet121, InceptionV3, VGG16\n",
    "channels_first = True\n",
    "GPU = True\n",
    "model_list = {\"ResNet18\":ResNet18, \"MobileNetV3\":MobileNetV3Small, \"ResNet50\":ResNet50, \"SqueezeNet\":SqueezeNet_11, \"ShuffleNet\":ShuffleNet,\n",
    "              \"Inception3\":InceptionV3, \"DenseNet\":DenseNet121, \n",
    "             \"Vit\":vit.vit_b16} \n",
    "\n",
    "\n",
    "INPUT_SHAPE = [1, 3, 224, 224] if channels_first else [1, 224, 224, 3]\n",
    "backend.set_image_data_format('channels_first' if channels_first else 'channels_last')\n",
    "input = np.random.uniform(low=0.0, high=1.0, size=(1, 3, 224, 224) if channels_first else (1, 224, 224, 3)).astype(np.float32)\n",
    "\n",
    "for modelname, Model in model_list.items():\n",
    "    \n",
    "    if modelname == \"Vit\":\n",
    "        base_model = Model(image_size=224, activation='relu', pretrained=False, include_top=True, pretrained_top=False, channel_first=channels_first)\n",
    "    elif modelname == \"SqueezeNet\":\n",
    "        base_model = Model(input_shape=tuple(INPUT_SHAPE[1:]), nb_classes=1000, channel_first=channels_first)\n",
    "    elif modelname == \"ShuffleNet\":\n",
    "        base_model = Model(include_top=True, input_shape=tuple(INPUT_SHAPE[1:]))\n",
    "    elif modelname == \"ResNet18\":\n",
    "        base_model = Model(classes=1000, input_shape=tuple(INPUT_SHAPE[1:]))\n",
    "    else:\n",
    "        base_model = Model(weights=None, include_top=True, input_shape=tuple(INPUT_SHAPE[1:]))\n",
    "        \n",
    "    model_name = base_model.name\n",
    "\n",
    "    transformer = True if model_name.find(\"Transformer\") > 0 or model_name.find(\"vit\") >= 0 else False\n",
    "    t1_start = time.perf_counter()\n",
    "\n",
    "    model = UFrontKeras(base_model, inputs = [input], batch_size = 1, transformer=transformer, pass_weights=True)\n",
    "\n",
    "    if transformer:\n",
    "      last_op = model.get_output_operator()\n",
    "      output = model.umodel().softmax(input=last_op.get_output(0), name=\"softmax_out\")\n",
    "\n",
    "    model.compile(optimizer={\"type\":\"sgd\", \"lr\":\"0.01\", \"momentum\":\"0\", \"nesterov\":\"False\", \"weight_decay\":\"0\"},\n",
    "                        loss='sparse_categorical_crossentropy', metrics=['accuracy', 'sparse_categorical_crossentropy'])\n",
    "    \n",
    "    # modelir= model.dump_ir()\n",
    "\n",
    "    tosa_ir= model.dump_tosa_ir()\n",
    "    t1_stop = time.perf_counter()\n",
    "    print(\"Compiling TOSA model...\")\n",
    "    if GPU:\n",
    "        binary = ireec.compile_str(tosa_ir,\n",
    "                        target_backends=[\"cuda\"], \n",
    "                        input_type=ireec.InputType.TOSA)\n",
    "        module = runtime.load_vm_flatbuffer(binary, driver=\"cuda\")\n",
    "    else:\n",
    "        binary = ireec.compile_str(tosa_ir,\n",
    "                        target_backends=[\"llvm-cpu\"], \n",
    "                        input_type=ireec.InputType.TOSA)\n",
    "        module = runtime.load_vm_flatbuffer(binary,backend=\"llvm-cpu\") \n",
    "\n",
    "    t2_stop = time.perf_counter()\n",
    "    print(modelname + \"****Ufront->TOSA Time: {:.3f}s, TOSA->Binary Time: {:.3f}s, Total Time: {:.3f}s\".format(t1_stop - t1_start, t2_stop - t1_stop, t2_stop - t1_start)) # print performance indicator\n",
    "\n",
    "    %timeit -n 100 ufront_ret = module.forward(input)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d1f044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
